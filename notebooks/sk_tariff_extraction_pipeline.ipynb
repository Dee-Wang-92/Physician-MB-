{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saskatchewan Tariff Extraction Pipeline\n",
    "\n",
    "**Phase 1**: Extract tariff codes with L1/L2/L3/L4 hierarchy  \n",
    "**Phase 2**: GPT enrichment for metadata extraction\n",
    "\n",
    "**Features:**\n",
    "- Extracts physician billing codes from Saskatchewan's Payment Schedule\n",
    "- Hierarchical categorization (Section → Category → Subcategory)\n",
    "- AI-powered enrichment: parent codes, add-ons, restrictions, exclusions\n",
    "- Checkpointing for crash recovery during long runs\n",
    "\n",
    "**Key differences from Manitoba:**\n",
    "- Code format: alphanumeric (70A, 153A) vs 4-digit\n",
    "- Fee format: $30.00 vs ...30.00\n",
    "- Section structure: Section A-Y vs body systems\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai -q\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Tuple, Dict\n",
    "from openai import OpenAI\n",
    "from google.colab import files, userdata\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "print(\"✓ Imports ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload source file\n",
    "print(\"Upload the marked-up SK payment schedule text file (sk_marked.txt)\")\n",
    "uploaded = files.upload()\n",
    "SOURCE_FILE = list(uploaded.keys())[0]\n",
    "with open(SOURCE_FILE, 'r', encoding='utf-8') as f:\n",
    "    RAW_TEXT = f.read()\n",
    "LINES = RAW_TEXT.split('\\n')\n",
    "print(f\"✓ {len(LINES):,} lines loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuration & Constants\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION CONSTANTS - MODIFIED FOR SASKATCHEWAN\n",
    "# =============================================================================\n",
    "\n",
    "# Extraction settings - SK uses \"S E C T I O N  A\" format\n",
    "CONTENT_START_MARKER = '«L1:S E C T I O N'\n",
    "CONTENT_START_MIN_LINE = 1000\n",
    "HIERARCHY_LOOKAHEAD_LINES = 5\n",
    "\n",
    "# Output settings\n",
    "MAX_DESCRIPTION_LENGTH = 500\n",
    "MAX_NOTES_LENGTH = 1000\n",
    "MAX_CONTEXT_LENGTH = 3500\n",
    "\n",
    "# GPT settings\n",
    "GPT_MODEL = \"gpt-4o\"\n",
    "GPT_TEMPERATURE = 0\n",
    "API_CALL_DELAY_SECONDS = 0.1\n",
    "COST_PER_ENTRY_ESTIMATE = 0.005\n",
    "TIME_PER_ENTRY_SECONDS = 0.5\n",
    "\n",
    "# Progress reporting\n",
    "PROGRESS_REPORT_INTERVAL = 25\n",
    "\n",
    "# Checkpointing settings\n",
    "CHECKPOINT_INTERVAL = 100  # Save checkpoint every N entries\n",
    "CHECKPOINT_FILE = 'SK_phase2_checkpoint.json'\n",
    "\n",
    "# Fee parsing - SK uses dollar amounts like $30.00\n",
    "# No unit value detection for SK (different format)\n",
    "\n",
    "# Section code mappings - SK uses Section letters A-Y\n",
    "# SK sections are explicitly named (Section A, B, C...) not body systems\n",
    "SECTION_PATTERNS = [\n",
    "    (r'section\\s*a\\s*[–-]|general\\s+services', 'A'),\n",
    "    (r'section\\s*b\\s*[–-]|general\\s+practice', 'B'),\n",
    "    (r'section\\s*c\\s*[–-]|internal\\s+medicine', 'C'),\n",
    "    (r'section\\s*d\\s*[–-]|pediatric', 'D'),\n",
    "    (r'section\\s*e\\s*[–-]|dermatology', 'E'),\n",
    "    (r'section\\s*f\\s*[–-]|neurology', 'F'),\n",
    "    (r'section\\s*g\\s*[–-]|psychiatry', 'G'),\n",
    "    (r'section\\s*h\\s*[–-]|anesthesia', 'H'),\n",
    "    (r'section\\s*i\\s*[–-]|obstetrics', 'I'),\n",
    "    (r'section\\s*j\\s*[–-]|ophthalmology', 'J'),\n",
    "    (r'section\\s*k\\s*[–-]|otolaryngology', 'K'),\n",
    "    (r'section\\s*l\\s*[–-]|general\\s+surgery', 'L'),\n",
    "    (r'section\\s*m\\s*[–-]|cardiac|cardiovascular', 'M'),\n",
    "    (r'section\\s*n\\s*[–-]|plastic', 'N'),\n",
    "    (r'section\\s*o\\s*[–-]|neurosurgery', 'O'),\n",
    "    (r'section\\s*p\\s*[–-]|orthopedic', 'P'),\n",
    "    (r'section\\s*q\\s*[–-]|thoracic', 'Q'),\n",
    "    (r'section\\s*r\\s*[–-]|urology', 'R'),\n",
    "    (r'section\\s*s\\s*[–-]|physical\\s+medicine', 'S'),\n",
    "    (r'section\\s*t\\s*[–-]|emergency', 'T'),\n",
    "    (r'section\\s*v\\s*[–-]|laboratory', 'V'),\n",
    "    (r'section\\s*w\\s*[–-]|diagnostic\\s+radiology', 'W'),\n",
    "    (r'section\\s*x\\s*[–-]|nuclear|radiation', 'X'),\n",
    "    (r'section\\s*y\\s*[–-]|pathology', 'Y'),\n",
    "]\n",
    "\n",
    "# Add-on detection patterns\n",
    "ADD_ON_PATTERNS = [\n",
    "    r'\\badd\\b', r'\\badd-on\\b', r'\\badditional\\b', r'\\bsupplement\\b',\n",
    "    r'\\beach additional\\b', r'\\bper additional\\b', r'\\badd to\\b',\n",
    "]\n",
    "\n",
    "# Final output column order\n",
    "OUTPUT_COLUMNS = [\n",
    "    'tariff_code', 'tariff_code_display', 'parent_code',\n",
    "    'section_code', 'section_name', 'specialty_code', 'specialty_name',\n",
    "    'category', 'subcategory', 'subsubcategory',\n",
    "    'description', 'notes',\n",
    "    'fee_specialist', 'fee_gp',\n",
    "    'is_add_on', 'add_on_to',\n",
    "    'age_restriction', 'setting_restriction', 'exclusions',\n",
    "    'is_provisional', 'is_asterisked', 'is_by_report',\n",
    "    'is_cross_reference', 'cross_reference_to',\n",
    "    'applicable_rules', 'time_requirement_minutes'\n",
    "]\n",
    "\n",
    "print(\"✓ Configuration constants defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 1: Extraction with L1/L2/L3 Hierarchy\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TEXT CLEANING UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Normalize dashes and clean encoding issues.\"\"\"\n",
    "    text = text.replace('—', '-')\n",
    "    text = text.replace('–', '-')\n",
    "    text = text.replace('−', '-')\n",
    "    text = text.replace('‐', '-')\n",
    "    text = text.replace('\\u00a0', ' ')\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def to_title_case(text: str) -> str:\n",
    "    \"\"\"Convert text to title case, handling special patterns.\"\"\"\n",
    "    if pd.isna(text) or not str(text).strip():\n",
    "        return text\n",
    "    text = str(text).strip()\n",
    "\n",
    "    # Handle 'S E C T I O N' pattern (spaced letters)\n",
    "    if re.match(r'^[A-Z]\\s+[A-Z]', text):\n",
    "        text = re.sub(r'\\b([A-Z])\\s+([A-Z]+)', r'\\1\\2', text)\n",
    "        text = re.sub(r'\\s*,\\s*', ', ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    text = text.title()\n",
    "\n",
    "    # Preserve lowercase for small words\n",
    "    for word in ['And', 'Or', 'The', 'A', 'An', 'Of', 'In', 'For', 'To', 'By']:\n",
    "        text = re.sub(r'\\s' + word + r'\\s', ' ' + word.lower() + ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "print(\"✓ Text cleaning utilities defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION AND SPECIALTY LOOKUPS - MODIFIED FOR SK\n",
    "# =============================================================================\n",
    "\n",
    "def get_section_code(l1_text: str) -> str:\n",
    "    \"\"\"Map L1 section text to section code (A-Y).\"\"\"\n",
    "    l1_lower = l1_text.lower()\n",
    "    \n",
    "    # SK format: \"S E C T I O N  A – General Services\" \n",
    "    # Extract section letter directly\n",
    "    match = re.search(r's\\s*e\\s*c\\s*t\\s*i\\s*o\\s*n\\s+([a-y])\\s*[–-]', l1_lower)\n",
    "    if match:\n",
    "        return match.group(1).upper()\n",
    "    \n",
    "    # Fallback to pattern matching\n",
    "    for pattern, code in SECTION_PATTERNS:\n",
    "        if re.search(pattern, l1_lower):\n",
    "            return code\n",
    "    return ''\n",
    "\n",
    "\n",
    "def get_specialty_info(l1_text: str) -> Tuple[str, str]:\n",
    "    \"\"\"Extract specialty code and name from L1 text.\"\"\"\n",
    "    # SK format: \"S E C T I O N  A – General Services\"\n",
    "    match = re.search(r's\\s*e\\s*c\\s*t\\s*i\\s*o\\s*n\\s+([a-y])\\s*[–-]\\s*(.+)', l1_text, re.IGNORECASE)\n",
    "    if match:\n",
    "        section_letter = match.group(1).upper()\n",
    "        section_name = match.group(2).strip()\n",
    "        return section_letter, section_name\n",
    "    return '', ''\n",
    "\n",
    "\n",
    "print(\"✓ Section and specialty lookups defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEE AND CONTENT EXTRACTION - MODIFIED FOR SK\n",
    "# =============================================================================\n",
    "\n",
    "def find_content_start(lines: List[str]) -> int:\n",
    "    \"\"\"Find the line where main content begins (Section A).\"\"\"\n",
    "    for i, line in enumerate(lines):\n",
    "        # SK starts at \"S E C T I O N  A\"\n",
    "        if CONTENT_START_MARKER in line and i > CONTENT_START_MIN_LINE:\n",
    "            return i\n",
    "        # Alternative: look for Section A pattern\n",
    "        if re.search(r'«L1:S\\s*E\\s*C\\s*T\\s*I\\s*O\\s*N\\s+A', line, re.IGNORECASE) and i > 100:\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "\n",
    "def parse_fee(val: str) -> float:\n",
    "    \"\"\"Parse fee string, handling comma-separated thousands and $ signs.\"\"\"\n",
    "    val = val.replace(',', '').replace('$', '').strip()\n",
    "    return float(val)\n",
    "\n",
    "\n",
    "def extract_fee_from_block(block: str) -> dict:\n",
    "    \"\"\"Parse fee information from a code block - SK format.\n",
    "    \n",
    "    SK format: $30.00 $30.00 (Specialist, GP) or single $30.00\n",
    "    \"\"\"\n",
    "    result = {'fee_specialist': None, 'fee_gp': None, 'is_by_report': False}\n",
    "\n",
    "    if re.search(r'By Report', block, re.IGNORECASE):\n",
    "        result['is_by_report'] = True\n",
    "\n",
    "    # SK Fee pattern: $XX.XX (with optional comma for thousands)\n",
    "    FEE_PATTERN = r'\\$([\\d,]+\\.\\d{2})'\n",
    "\n",
    "    # Find all dollar amounts in the block\n",
    "    fees = re.findall(FEE_PATTERN, block)\n",
    "    \n",
    "    if len(fees) >= 2:\n",
    "        # Two fees: Specialist and GP\n",
    "        result['fee_specialist'] = parse_fee(fees[-2])  # Second to last\n",
    "        result['fee_gp'] = parse_fee(fees[-1])  # Last\n",
    "    elif len(fees) == 1:\n",
    "        # Single fee\n",
    "        result['fee_specialist'] = parse_fee(fees[0])\n",
    "        result['fee_gp'] = parse_fee(fees[0])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_description(block: str, code: str) -> str:\n",
    "    \"\"\"Extract and clean description text from a code block.\"\"\"\n",
    "    # Remove the CODE marker\n",
    "    text = re.sub(r'«CODE:~?\\d{1,4}[A-Z]\\*?»', '', block)\n",
    "    \n",
    "    lines = []\n",
    "    for line in text.split('\\n'):\n",
    "        # Stop at notes\n",
    "        if re.match(r'^\\s*Notes?:', line, re.IGNORECASE):\n",
    "            break\n",
    "        # Skip page headers/footers\n",
    "        if re.match(r'^\\s*April 1,|^Page\\s+\\d+|^\\f', line, re.IGNORECASE):\n",
    "            continue\n",
    "        if re.match(r'^Payment Schedule for Insured', line, re.IGNORECASE):\n",
    "            continue\n",
    "        if line.strip():\n",
    "            lines.append(line)\n",
    "    \n",
    "    desc = ' '.join(lines)\n",
    "    \n",
    "    # Remove the code at the start\n",
    "    desc = re.sub(r'^\\s*~?' + re.escape(code) + r'\\*?\\s*', '', desc)\n",
    "    \n",
    "    # Remove fee amounts\n",
    "    desc = re.sub(r'\\s*\\$[\\d,]+\\.\\d{2}', '', desc)\n",
    "    \n",
    "    # Remove trailing classification codes (D, 0, L, M, H, etc.)\n",
    "    desc = re.sub(r'\\s+[DLMH0-9]+\\s*$', '', desc)\n",
    "    \n",
    "    desc = clean_text(desc)\n",
    "    return desc[:MAX_DESCRIPTION_LENGTH]\n",
    "\n",
    "\n",
    "def extract_notes(block: str) -> str:\n",
    "    \"\"\"Extract notes section from a code block.\"\"\"\n",
    "    match = re.search(r'Notes?:\\s*(.+?)(?=«|$)', block, re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        notes = clean_text(match.group(1))\n",
    "        return notes[:MAX_NOTES_LENGTH]\n",
    "    return ''\n",
    "\n",
    "\n",
    "def check_cross_reference(block: str) -> Tuple[bool, str]:\n",
    "    \"\"\"Check if block contains a cross-reference to another section.\"\"\"\n",
    "    patterns = [r'See Section\\s*([A-Y])', r'See\\s+(General\\s+Services|Laboratory)']\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, block, re.IGNORECASE)\n",
    "        if match:\n",
    "            return True, match.group(1)\n",
    "    return False, ''\n",
    "\n",
    "\n",
    "def extract_rules(block: str) -> str:\n",
    "    \"\"\"Extract applicable rule references from a code block.\"\"\"\n",
    "    rules = set()\n",
    "    for match in re.finditer(r'Rules?\\s+(\\d+(?:\\s+to\\s+\\d+)?)', block, re.IGNORECASE):\n",
    "        rules.add(match.group(1))\n",
    "    return ', '.join(sorted(rules)) if rules else ''\n",
    "\n",
    "\n",
    "def extract_time_requirement(block: str) -> Optional[int]:\n",
    "    \"\"\"Extract minimum time requirement in minutes from a code block.\"\"\"\n",
    "    match = re.search(r'(\\d+)\\s*minutes?', block, re.IGNORECASE)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "\n",
    "def is_add_on_fee(block: str, description: str) -> bool:\n",
    "    \"\"\"Detect if this is an add-on fee based on text patterns.\"\"\"\n",
    "    text = (block + ' ' + description).lower()\n",
    "    for pattern in ADD_ON_PATTERNS:\n",
    "        if re.search(pattern, text):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "print(\"✓ Fee and content extraction functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HIERARCHY EXTRACTION\n",
    "# =============================================================================\n",
    "\n",
    "def extract_hierarchy_text(lines: List[str], start_idx: int, fallback_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract readable text for a hierarchy level marker.\n",
    "    \"\"\"\n",
    "    for k in range(start_idx + 1, min(start_idx + HIERARCHY_LOOKAHEAD_LINES, len(lines))):\n",
    "        next_line = lines[k].strip()\n",
    "        if next_line and not next_line.startswith('«') and not next_line.startswith('\\f'):\n",
    "            # For SK, handle the spaced SECTION pattern\n",
    "            cleaned = clean_text(next_line.split('$')[0])  # Remove fee amounts\n",
    "            return cleaned\n",
    "    return clean_text(fallback_text)\n",
    "\n",
    "\n",
    "class HierarchyTracker:\n",
    "    \"\"\"Tracks the current L1/L2/L3/L4 hierarchy state during extraction.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.l1 = \"\"\n",
    "        self.l2 = \"\"\n",
    "        self.l3 = \"\"\n",
    "        self.l4 = \"\"\n",
    "\n",
    "    def set_l1(self, value: str):\n",
    "        \"\"\"Set L1 and reset L2, L3, L4.\"\"\"\n",
    "        self.l1 = value\n",
    "        self.l2 = \"\"\n",
    "        self.l3 = \"\"\n",
    "        self.l4 = \"\"\n",
    "\n",
    "    def set_l2(self, value: str):\n",
    "        \"\"\"Set L2 and reset L3, L4.\"\"\"\n",
    "        self.l2 = value\n",
    "        self.l3 = \"\"\n",
    "        self.l4 = \"\"\n",
    "\n",
    "    def set_l3(self, value: str):\n",
    "        \"\"\"Set L3 and reset L4.\"\"\"\n",
    "        self.l3 = value\n",
    "        self.l4 = \"\"\n",
    "\n",
    "    def set_l4(self, value: str):\n",
    "        \"\"\"Set L4.\"\"\"\n",
    "        self.l4 = value\n",
    "\n",
    "    def get_current(self) -> Tuple[str, str, str, str]:\n",
    "        \"\"\"Return current hierarchy as tuple (l1, l2, l3, l4).\"\"\"\n",
    "        return self.l1, self.l2, self.l3, self.l4\n",
    "\n",
    "\n",
    "print(\"✓ Hierarchy extraction functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MAIN EXTRACTION FUNCTION - MODIFIED FOR SK CODE FORMAT\n",
    "# =============================================================================\n",
    "\n",
    "def run_extraction(lines: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Main extraction function with L1/L2/L3/L4 hierarchy - SK version.\"\"\"\n",
    "    entries = []\n",
    "    start_idx = find_content_start(lines)\n",
    "    print(f\"Content starts at line {start_idx}\")\n",
    "\n",
    "    hierarchy = HierarchyTracker()\n",
    "\n",
    "    # Regex patterns for hierarchy and code markers\n",
    "    hierarchy_patterns = [\n",
    "        (r'«L1:(.+?)»', hierarchy.set_l1),\n",
    "        (r'«L2:(.+?)»', hierarchy.set_l2),\n",
    "        (r'«L3:(.+?)»', hierarchy.set_l3),\n",
    "        (r'«L4:(.+?)»', hierarchy.set_l4),\n",
    "    ]\n",
    "    \n",
    "    # SK code pattern: digits followed by a letter (e.g., 70A, 153A, 5B)\n",
    "    # Optional ~ prefix for provisional, optional * suffix for asterisked\n",
    "    code_pattern = re.compile(r'«CODE:(~)?(\\d{1,4}[A-Z])(\\*)?»')\n",
    "    block_end_pattern = re.compile(r'«CODE:|«L1:|«L2:|«L3:|«L4:')\n",
    "\n",
    "    i = start_idx\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "\n",
    "        # Check for hierarchy markers\n",
    "        hierarchy_matched = False\n",
    "        for pattern, setter in hierarchy_patterns:\n",
    "            match = re.search(pattern, line)\n",
    "            if match:\n",
    "                readable = extract_hierarchy_text(lines, i, match.group(1))\n",
    "                setter(readable)\n",
    "                hierarchy_matched = True\n",
    "                break\n",
    "\n",
    "        if hierarchy_matched:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Check for CODE marker\n",
    "        code_match = code_pattern.search(line)\n",
    "        if code_match:\n",
    "            is_provisional_in_tag = code_match.group(1) is not None\n",
    "            code = code_match.group(2)  # e.g., \"70A\", \"153A\"\n",
    "            is_asterisked_in_tag = code_match.group(3) is not None\n",
    "            block_start = i\n",
    "\n",
    "            # Collect block lines until next marker\n",
    "            block_lines = [line]\n",
    "            j = i + 1\n",
    "            while j < len(lines):\n",
    "                next_line = lines[j]\n",
    "                if block_end_pattern.search(next_line):\n",
    "                    break\n",
    "                block_lines.append(next_line)\n",
    "                j += 1\n",
    "\n",
    "            block = '\\n'.join(block_lines)\n",
    "            fee_info = extract_fee_from_block(block)\n",
    "            is_xref, xref_to = check_cross_reference(block)\n",
    "\n",
    "            # Only include entries with fee, by-report, or cross-reference\n",
    "            if fee_info['fee_specialist'] is not None or fee_info['is_by_report'] or is_xref:\n",
    "                is_provisional = is_provisional_in_tag or bool(re.search(r'[@#]', block))\n",
    "                is_asterisked = is_asterisked_in_tag or bool(re.search(r'\\*', block))\n",
    "\n",
    "                l1, l2, l3, l4 = hierarchy.get_current()\n",
    "                section_code = get_section_code(l1)\n",
    "                specialty_code, specialty_name = get_specialty_info(l1)\n",
    "                description = extract_description(block, code)\n",
    "\n",
    "                display = code\n",
    "                if is_provisional:\n",
    "                    display = '~' + display\n",
    "                if is_asterisked:\n",
    "                    display = display + '*'\n",
    "\n",
    "                entries.append({\n",
    "                    'tariff_code': code,\n",
    "                    'tariff_code_display': display,\n",
    "                    'parent_code': None,\n",
    "                    'section_code': section_code,\n",
    "                    'section_name': l1,\n",
    "                    'specialty_code': specialty_code,\n",
    "                    'specialty_name': specialty_name,\n",
    "                    'category': l2,\n",
    "                    'subcategory': l3,\n",
    "                    'subsubcategory': l4,\n",
    "                    'description': description,\n",
    "                    'notes': extract_notes(block),\n",
    "                    'fee_specialist': fee_info['fee_specialist'],\n",
    "                    'fee_gp': fee_info['fee_gp'],\n",
    "                    'is_add_on': is_add_on_fee(block, description),\n",
    "                    'is_provisional': is_provisional,\n",
    "                    'is_asterisked': is_asterisked,\n",
    "                    'is_by_report': fee_info['is_by_report'],\n",
    "                    'is_cross_reference': is_xref,\n",
    "                    'cross_reference_to': xref_to,\n",
    "                    'applicable_rules': extract_rules(block),\n",
    "                    'time_requirement_minutes': extract_time_requirement(block),\n",
    "                    'source_line': block_start + 1,\n",
    "                })\n",
    "\n",
    "            i = j\n",
    "            continue\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return pd.DataFrame(entries)\n",
    "\n",
    "\n",
    "print(\"✓ Main extraction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RUN PHASE 1 EXTRACTION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PHASE 1: EXTRACTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df = run_extraction(LINES)\n",
    "\n",
    "print(f\"\\n✓ Extracted {len(df):,} entries\")\n",
    "print(f\"  Unique codes: {df['tariff_code'].nunique():,}\")\n",
    "print(f\"  Has specialist fee: {df['fee_specialist'].notna().sum():,} ({100*df['fee_specialist'].notna().sum()/len(df):.1f}%)\")\n",
    "print(f\"  By Report: {df['is_by_report'].sum():,}\")\n",
    "print(f\"  Add-on fees: {df['is_add_on'].sum():,}\")\n",
    "print(f\"\\nHierarchy coverage:\")\n",
    "print(f\"  Has L1 (section_name): {(df['section_name'] != '').sum():,}\")\n",
    "print(f\"  Has L2 (category): {(df['category'] != '').sum():,}\")\n",
    "print(f\"  Has L3 (subcategory): {(df['subcategory'] != '').sum():,}\")\n",
    "print(f\"  Has L4 (subsubcategory): {(df['subsubcategory'] != '').sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show hierarchy examples\n",
    "print(\"Sample hierarchy:\")\n",
    "sample = df.head(20)\n",
    "for idx, row in sample.iterrows():\n",
    "    print(f\"\\n{row['tariff_code']}:\")\n",
    "    print(f\"  L1: {row['section_name'][:50] if row['section_name'] else '(none)'}\")\n",
    "    print(f\"  L2: {row['category'][:40] if row['category'] else '(none)'}\")\n",
    "    print(f\"  L3: {row['subcategory'][:40] if row['subcategory'] else '(none)'}\")\n",
    "    print(f\"  Desc: {row['description'][:40] if row['description'] else '(none)'}\")\n",
    "    print(f\"  Fee: ${row['fee_specialist']} / ${row['fee_gp']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate known SK codes\n",
    "print(\"\\nKnown code validation (SK):\")\n",
    "KNOWN_CODES = [\n",
    "    ('70A', 30.00),\n",
    "    ('71A', 55.00),\n",
    "    ('74A', 140.00),\n",
    "    ('153A', 30.40),\n",
    "]\n",
    "\n",
    "for code, expected_fee in KNOWN_CODES:\n",
    "    matches = df[df['tariff_code'] == code]\n",
    "    if len(matches) > 0:\n",
    "        actual = matches.iloc[0]['fee_specialist']\n",
    "        status = '✓' if actual and abs(actual - expected_fee) < 0.01 else f'✗ got {actual}'\n",
    "        print(f\"  {code}: {expected_fee} -> {status}\")\n",
    "    else:\n",
    "        print(f\"  {code}: NOT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply title case cleaning to text columns\n",
    "TEXT_COLUMNS = ['section_name', 'category', 'subcategory', 'subsubcategory', 'description']\n",
    "\n",
    "for col in TEXT_COLUMNS:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(to_title_case)\n",
    "\n",
    "print(\"✓ Data cleaning applied (title case)\")\n",
    "print(f\"\\nSample cleaned data:\")\n",
    "sample = df[['tariff_code', 'section_name', 'category', 'subcategory', 'description']].head(10)\n",
    "for idx, row in sample.iterrows():\n",
    "    category_display = row['category'][:30] if row['category'] else '(none)'\n",
    "    print(f\"  {row['tariff_code']}: {category_display} > {row['description'][:30] if row['description'] else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "def prefix_for_excel(value, prefix=\"'\"):\n",
    "    \"\"\"Prefix a value to prevent Excel auto-formatting.\"\"\"\n",
    "    if pd.isna(value) or value == '' or value is None:\n",
    "        return value\n",
    "    return f\"{prefix}{value}\"\n",
    "\n",
    "\n",
    "def clean_tariff_code(x):\n",
    "    \"\"\"Clean and format a single tariff code (SK format: alphanumeric).\"\"\"\n",
    "    if pd.isna(x) or x == '' or x is None:\n",
    "        return None\n",
    "    return str(x).strip().upper()\n",
    "\n",
    "\n",
    "def clean_tariff_code_list(x):\n",
    "    \"\"\"Clean and format a comma-separated list of tariff codes.\"\"\"\n",
    "    if pd.isna(x) or x == '' or x is None:\n",
    "        return None\n",
    "    codes = [c.strip().upper() for c in str(x).split(',')]\n",
    "    return ', '.join(codes)\n",
    "\n",
    "\n",
    "print(\"✓ Export utilities defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Phase 1 output\n",
    "PHASE1_FILE = 'sk_tariffs_phase1.csv'\n",
    "\n",
    "df_phase1 = df.copy()\n",
    "df_phase1['tariff_code'] = df_phase1['tariff_code'].apply(lambda x: prefix_for_excel(x))\n",
    "df_phase1['specialty_code'] = df_phase1['specialty_code'].apply(\n",
    "    lambda x: prefix_for_excel(x) if x != '' else x\n",
    ")\n",
    "\n",
    "df_phase1.to_csv(PHASE1_FILE, index=False, encoding='utf-8')\n",
    "print(f\"✓ Phase 1 export saved: {PHASE1_FILE}\")\n",
    "print(f\"  {len(df)} rows, {len(df.columns)} columns\")\n",
    "files.download(PHASE1_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 2: GPT Full Review\n",
    "\n",
    "GPT reviews ALL entries for:\n",
    "- Description completion (if L1+L2+L3+L4+desc insufficient)\n",
    "- Parent code relationships\n",
    "- Add-on fee detection (is_add_on, add_on_to)\n",
    "- Age restrictions\n",
    "- Setting restrictions\n",
    "- Exclusions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup OpenAI (secure API key input - key will NOT be displayed)\n",
    "try:\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"✓ API key loaded from Colab secrets\")\n",
    "except:\n",
    "    OPENAI_API_KEY = getpass.getpass(\"Enter OpenAI API key (input hidden): \")\n",
    "    print(\"✓ API key entered\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "print(\"✓ OpenAI client ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2 cost and time estimates\n",
    "total_entries = len(df)\n",
    "estimated_cost = total_entries * COST_PER_ENTRY_ESTIMATE\n",
    "estimated_minutes = total_entries * TIME_PER_ENTRY_SECONDS / 60\n",
    "\n",
    "print(f\"Total entries to review: {total_entries}\")\n",
    "print(f\"Estimated cost: ~${estimated_cost:.2f}\")\n",
    "print(f\"Estimated time: ~{estimated_minutes:.0f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GPT REVIEW SYSTEM PROMPT - MODIFIED FOR SASKATCHEWAN\n",
    "# =============================================================================\n",
    "\n",
    "SYSTEM_PROMPT = '''You are an expert medical billing coder reviewing Saskatchewan's Payment Schedule for Insured Services.\n",
    "\n",
    "IMPORTANT: Saskatchewan uses ALPHANUMERIC codes (e.g., 70A, 153A, 5B) not 4-digit codes.\n",
    "\n",
    "For EACH code, extract the following:\n",
    "\n",
    "═══════════════════════════════════════════════════════════════\n",
    "1. DESCRIPTION COMPLETION\n",
    "═══════════════════════════════════════════════════════════════\n",
    "L1, L2, L3, L4 are ALREADY stored in separate columns.\n",
    "Do NOT repeat them in the description.\n",
    "\n",
    "If a description seems incomplete:\n",
    "- Set parent_code to link it to its parent\n",
    "- KEEP the description SHORT as-is\n",
    "- Users can follow the parent_code chain to get full meaning\n",
    "\n",
    "═══════════════════════════════════════════════════════════════\n",
    "2. PARENT_CODE\n",
    "═══════════════════════════════════════════════════════════════\n",
    "\n",
    "A child code is a code whose description is incomplete on its own.\n",
    "Look at INDENTATION in the source context to identify relationships.\n",
    "\n",
    "SET parent_code TO THE IMMEDIATE PARENT:\n",
    "    70A     Telephone call from SGI...              → parent_code: null\n",
    "    71A     Written letter requested by SGI...      → parent_code: null\n",
    "    74A     Examination and Report for SGI...       → parent_code: null\n",
    "    \n",
    "For procedure variants:\n",
    "    100A    Collection of blood from donor          → parent_code: null  \n",
    "    101A    Phlebotomy for therapeutic reason       → parent_code: null (different procedure)\n",
    "    \n",
    "For tiered codes:\n",
    "    80A     Third Party Counselling - first 15 min  → parent_code: null\n",
    "    81A     Third Party Counselling - next 15 min   → parent_code: \"80A\"\n",
    "\n",
    "The parent_code must be an alphanumeric code VISIBLE in the nearby context.\n",
    "\n",
    "═══════════════════════════════════════════════════════════════\n",
    "3. ADD-ON DETECTION\n",
    "═══════════════════════════════════════════════════════════════\n",
    "is_add_on = true ONLY when THIS CODE is explicitly a supplement\n",
    "that gets billed ON TOP OF another service.\n",
    "\n",
    "DEFINITE ADD-ONS (is_add_on: true):\n",
    "- Description contains \"add to\" or \"supplement\"\n",
    "- Notes say THIS code \"may be claimed in addition to\" other codes\n",
    "\n",
    "NOT ADD-ONS (is_add_on: false):\n",
    "- Regular visit/examination codes\n",
    "- \"Each additional X\" patterns - these are VARIANTS, use parent_code\n",
    "\n",
    "═══════════════════════════════════════════════════════════════\n",
    "4. AGE RESTRICTION (only if EXPLICITLY stated)\n",
    "═══════════════════════════════════════════════════════════════\n",
    "Look for: \"under 18\", \"child\", \"pediatric\", \"over 65\", \"elderly\", \"newborn\"\n",
    "Return the exact restriction text. null if not mentioned.\n",
    "\n",
    "═══════════════════════════════════════════════════════════════\n",
    "5. SETTING RESTRICTION (only if EXPLICITLY stated)\n",
    "═══════════════════════════════════════════════════════════════\n",
    "Look for: \"hospital only\", \"office\", \"home\", \"ICU\", \"Emergency\"\n",
    "Return the exact restriction text. null if not mentioned.\n",
    "\n",
    "═══════════════════════════════════════════════════════════════\n",
    "6. EXCLUSIONS (only if EXPLICITLY stated)\n",
    "═══════════════════════════════════════════════════════════════\n",
    "Look for: \"cannot be claimed with\", \"may not be claimed with\", \"excludes\"\n",
    "Return the exact exclusion text. null if not mentioned.\n",
    "\n",
    "═══════════════════════════════════════════════════════════════\n",
    "SK-SPECIFIC NOTES\n",
    "═══════════════════════════════════════════════════════════════\n",
    "- Codes marked with @ or # require entitlement/approval → is_provisional=true\n",
    "- Codes with * after fee → is_asterisked=true (age supplement applies)\n",
    "- Fee format: $XX.XX $XX.XX (Specialist, GP)\n",
    "\n",
    "Return JSON:\n",
    "{\n",
    "  \"needs_completion\": true/false,\n",
    "  \"description\": \"...\",\n",
    "  \"parent_code\": \"XXA\" or null,\n",
    "  \"is_add_on\": true/false,\n",
    "  \"add_on_to\": \"XXA, YYB\" or null,\n",
    "  \"age_restriction\": \"...\" or null,\n",
    "  \"setting_restriction\": \"...\" or null,\n",
    "  \"exclusions\": \"...\" or null\n",
    "}\n",
    "'''\n",
    "\n",
    "print(\"✓ System prompt defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GPT EVALUATION FUNCTIONS - MODIFIED FOR SK CODE FORMAT\n",
    "# =============================================================================\n",
    "\n",
    "def get_source_context(source_line: int, lines: List[str], before: int = 30, after: int = 5) -> str:\n",
    "    \"\"\"Get surrounding context from source file for GPT review.\"\"\"\n",
    "    if pd.isna(source_line) or source_line < 1:\n",
    "        return \"(no source context available)\"\n",
    "    source_line = int(source_line)\n",
    "    start = max(0, source_line - before - 1)\n",
    "    end = min(len(lines), source_line + after)\n",
    "    context = '\\n'.join(lines[start:end])\n",
    "    context = context.replace('\\f', '\\n').strip()\n",
    "    return context[:MAX_CONTEXT_LENGTH]\n",
    "\n",
    "\n",
    "def build_user_message(row: pd.Series, context: str) -> str:\n",
    "    \"\"\"Build the user message for GPT review.\"\"\"\n",
    "    return f\"\"\"Code: {row['tariff_code']}\n",
    "\n",
    "HIERARCHY:\n",
    "  L1 (section): {row['section_name']}\n",
    "  L2 (category): {row['category'] if row['category'] else '(none)'}\n",
    "  L3 (subcategory): {row['subcategory'] if row['subcategory'] else '(none)'}\n",
    "  L4 (subsubcategory): {row['subsubcategory'] if row['subsubcategory'] else '(none)'}\n",
    "\n",
    "Description: \"{row['description']}\"\n",
    "Notes: \"{row['notes'] if row['notes'] else '(none)'}\"\n",
    "\n",
    "Source context:\n",
    "```\n",
    "{context}\n",
    "```\"\"\"\n",
    "\n",
    "\n",
    "def parse_gpt_response(result: Dict, original_description: str) -> Dict:\n",
    "    \"\"\"Parse and clean GPT response - SK version.\"\"\"\n",
    "    # Clean description\n",
    "    desc = result.get('description', original_description)\n",
    "    desc = clean_text(desc)\n",
    "    if len(desc) > MAX_DESCRIPTION_LENGTH:\n",
    "        desc = desc[:MAX_DESCRIPTION_LENGTH - 3] + '...'\n",
    "\n",
    "    # Clean parent_code (SK format: alphanumeric like 70A)\n",
    "    parent = result.get('parent_code')\n",
    "    if parent:\n",
    "        parent = str(parent).strip().upper()\n",
    "        if not re.match(r'^\\d{1,4}[A-Z]$', parent):\n",
    "            parent = None\n",
    "\n",
    "    # Clean add_on_to\n",
    "    add_on_to = result.get('add_on_to')\n",
    "    if add_on_to:\n",
    "        add_on_to = str(add_on_to).strip().upper()\n",
    "        codes = [c.strip() for c in add_on_to.split(',')]\n",
    "        codes = [c for c in codes if re.match(r'^\\d{1,4}[A-Z]$', c)]\n",
    "        add_on_to = ', '.join(codes) if codes else None\n",
    "\n",
    "    return {\n",
    "        'needs_completion': result.get('needs_completion', False),\n",
    "        'description': desc,\n",
    "        'parent_code': parent,\n",
    "        'is_add_on': result.get('is_add_on', False),\n",
    "        'add_on_to': add_on_to,\n",
    "        'age_restriction': result.get('age_restriction'),\n",
    "        'setting_restriction': result.get('setting_restriction'),\n",
    "        'exclusions': result.get('exclusions')\n",
    "    }\n",
    "\n",
    "\n",
    "def get_empty_result(original_description: str) -> Dict:\n",
    "    \"\"\"Return empty result for error cases.\"\"\"\n",
    "    return {\n",
    "        'needs_completion': False,\n",
    "        'description': original_description,\n",
    "        'parent_code': None,\n",
    "        'is_add_on': False,\n",
    "        'add_on_to': None,\n",
    "        'age_restriction': None,\n",
    "        'setting_restriction': None,\n",
    "        'exclusions': None\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_entry(row: pd.Series, lines: List[str]) -> Dict:\n",
    "    \"\"\"Send entry to GPT for full evaluation.\"\"\"\n",
    "    context = get_source_context(row['source_line'], lines)\n",
    "    user_msg = build_user_message(row, context)\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=GPT_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": user_msg}\n",
    "            ],\n",
    "            temperature=GPT_TEMPERATURE,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        result = json.loads(response.choices[0].message.content)\n",
    "        return parse_gpt_response(result, row['description'])\n",
    "    except Exception as e:\n",
    "        print(f\"  Error on {row['tariff_code']}: {e}\")\n",
    "        return get_empty_result(row['description'])\n",
    "\n",
    "\n",
    "print(\"✓ GPT evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CHECKPOINTING FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def save_checkpoint(results: Dict, stats: Dict, last_processed_idx: int, checkpoint_file: str = CHECKPOINT_FILE):\n",
    "    \"\"\"Save current progress to a checkpoint file.\"\"\"\n",
    "    checkpoint_data = {\n",
    "        'results': {str(k): v for k, v in results.items()},\n",
    "        'stats': stats,\n",
    "        'last_processed_idx': last_processed_idx,\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    with open(checkpoint_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(checkpoint_data, f, indent=2)\n",
    "    print(f\"  [Checkpoint saved: {last_processed_idx + 1} entries]\")\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_file: str = CHECKPOINT_FILE) -> Tuple[Dict, Dict, int]:\n",
    "    \"\"\"Load progress from a checkpoint file if it exists.\"\"\"\n",
    "    if not os.path.exists(checkpoint_file):\n",
    "        return {}, {'completed': 0, 'parents': 0, 'add_ons': 0, 'age_restricted': 0, 'setting_restricted': 0, 'has_exclusions': 0}, -1\n",
    "\n",
    "    try:\n",
    "        with open(checkpoint_file, 'r', encoding='utf-8') as f:\n",
    "            checkpoint_data = json.load(f)\n",
    "\n",
    "        results = {int(k): v for k, v in checkpoint_data['results'].items()}\n",
    "        stats = checkpoint_data['stats']\n",
    "        last_processed_idx = checkpoint_data['last_processed_idx']\n",
    "\n",
    "        print(f\"✓ Loaded checkpoint from {checkpoint_data['timestamp']}\")\n",
    "        print(f\"  Resuming from entry {last_processed_idx + 1}\")\n",
    "        print(f\"  Stats so far: completions={stats['completed']}, parents={stats['parents']}, add-ons={stats['add_ons']}\")\n",
    "\n",
    "        return results, stats, last_processed_idx\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load checkpoint ({e}). Starting fresh.\")\n",
    "        return {}, {'completed': 0, 'parents': 0, 'add_ons': 0, 'age_restricted': 0, 'setting_restricted': 0, 'has_exclusions': 0}, -1\n",
    "\n",
    "\n",
    "def clear_checkpoint(checkpoint_file: str = CHECKPOINT_FILE):\n",
    "    \"\"\"Remove checkpoint file after successful completion.\"\"\"\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        os.remove(checkpoint_file)\n",
    "        print(f\"✓ Checkpoint file removed\")\n",
    "\n",
    "\n",
    "print(\"✓ Checkpointing functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TEST CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "TEST_MODE = False  # Set to False for full run\n",
    "TEST_LIMIT = 50\n",
    "\n",
    "if TEST_MODE:\n",
    "    process_df = df.head(TEST_LIMIT).copy()\n",
    "    print(f\"✓ TEST MODE: First {len(process_df)} entries\")\n",
    "else:\n",
    "    process_df = df.copy()\n",
    "    print(f\"FULL RUN: Processing all {len(process_df)} entries\")\n",
    "\n",
    "print(f\"\\nEstimated time: ~{len(process_df) * TIME_PER_ENTRY_SECONDS / 60:.1f} minutes\")\n",
    "print(f\"Estimated cost: ~${len(process_df) * COST_PER_ENTRY_ESTIMATE:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RUN PHASE 2 GPT REVIEW (with checkpointing)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PHASE 2: GPT FULL REVIEW\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "results, stats, last_processed_idx = load_checkpoint()\n",
    "\n",
    "entries_to_process = list(enumerate(process_df.iterrows()))\n",
    "start_position = last_processed_idx + 1\n",
    "\n",
    "if start_position > 0:\n",
    "    print(f\"Skipping {start_position} already-processed entries...\")\n",
    "\n",
    "for i, (idx, row) in entries_to_process[start_position:]:\n",
    "    if (i + 1) % PROGRESS_REPORT_INTERVAL == 0:\n",
    "        print(f\"  {i+1}/{len(process_df)} - completions:{stats['completed']}, parents:{stats['parents']}, add-ons:{stats['add_ons']}\")\n",
    "\n",
    "    result = evaluate_entry(row, LINES)\n",
    "    results[idx] = result\n",
    "\n",
    "    if result['needs_completion']:\n",
    "        stats['completed'] += 1\n",
    "    if result['parent_code']:\n",
    "        stats['parents'] += 1\n",
    "    if result['is_add_on']:\n",
    "        stats['add_ons'] += 1\n",
    "    if result['age_restriction']:\n",
    "        stats['age_restricted'] += 1\n",
    "    if result['setting_restriction']:\n",
    "        stats['setting_restricted'] += 1\n",
    "    if result['exclusions']:\n",
    "        stats['has_exclusions'] += 1\n",
    "\n",
    "    if (i + 1) % CHECKPOINT_INTERVAL == 0:\n",
    "        save_checkpoint(results, stats, i)\n",
    "\n",
    "    time.sleep(API_CALL_DELAY_SECONDS)\n",
    "\n",
    "save_checkpoint(results, stats, len(process_df) - 1)\n",
    "\n",
    "print(f\"\\n✓ Phase 2 complete!\")\n",
    "print(f\"  Descriptions completed: {stats['completed']}\")\n",
    "print(f\"  Parent codes: {stats['parents']}\")\n",
    "print(f\"  Add-on fees: {stats['add_ons']}\")\n",
    "print(f\"  Age restricted: {stats['age_restricted']}\")\n",
    "print(f\"  Setting restricted: {stats['setting_restricted']}\")\n",
    "print(f\"  Has exclusions: {stats['has_exclusions']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# APPLY GPT RESULTS TO DATAFRAME\n",
    "# =============================================================================\n",
    "\n",
    "df['_desc_original'] = df['description']\n",
    "df['add_on_to'] = None\n",
    "df['age_restriction'] = None\n",
    "df['setting_restriction'] = None\n",
    "df['exclusions'] = None\n",
    "\n",
    "for idx, result in results.items():\n",
    "    if result['needs_completion']:\n",
    "        df.loc[idx, 'description'] = result['description']\n",
    "    if result['parent_code']:\n",
    "        df.loc[idx, 'parent_code'] = result['parent_code']\n",
    "    df.loc[idx, 'is_add_on'] = result['is_add_on']\n",
    "    if result['add_on_to']:\n",
    "        df.loc[idx, 'add_on_to'] = result['add_on_to']\n",
    "    if result['age_restriction']:\n",
    "        df.loc[idx, 'age_restriction'] = result['age_restriction']\n",
    "    if result['setting_restriction']:\n",
    "        df.loc[idx, 'setting_restriction'] = result['setting_restriction']\n",
    "    if result['exclusions']:\n",
    "        df.loc[idx, 'exclusions'] = result['exclusions']\n",
    "\n",
    "print(f\"Applied {stats['completed']} description updates\")\n",
    "print(f\"Applied {stats['parents']} parent codes\")\n",
    "print(f\"Applied {stats['add_ons']} add-on flags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FINAL CLEANUP AND COLUMN ORDERING\n",
    "# =============================================================================\n",
    "\n",
    "drop_cols = ['_desc_original']\n",
    "df_final = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
    "\n",
    "df_final = df_final[[c for c in OUTPUT_COLUMNS if c in df_final.columns]]\n",
    "\n",
    "print(f\"Final dataset: {len(df_final)} rows x {len(df_final.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FINAL SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL SUMMARY - SASKATCHEWAN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTotal entries: {len(df_final):,}\")\n",
    "print(f\"Unique codes: {df_final['tariff_code'].nunique():,}\")\n",
    "\n",
    "print(f\"\\nFee coverage:\")\n",
    "print(f\"  Has specialist fee: {df_final['fee_specialist'].notna().sum():,} ({100*df_final['fee_specialist'].notna().sum()/len(df_final):.1f}%)\")\n",
    "print(f\"  By Report: {df_final['is_by_report'].sum():,}\")\n",
    "\n",
    "print(f\"\\nHierarchy:\")\n",
    "print(f\"  Has category (L2): {(df_final['category'] != '').sum():,}\")\n",
    "print(f\"  Has subcategory (L3): {(df_final['subcategory'] != '').sum():,}\")\n",
    "print(f\"  Has subsubcategory (L4): {(df_final['subsubcategory'] != '').sum():,}\")\n",
    "\n",
    "print(f\"\\nGPT Review:\")\n",
    "print(f\"  Entries reviewed: {len(results)}\")\n",
    "print(f\"  Descriptions completed: {stats['completed']}\")\n",
    "print(f\"  Parent codes: {df_final['parent_code'].notna().sum():,}\")\n",
    "print(f\"  Add-on fees: {df_final['is_add_on'].sum():,}\")\n",
    "print(f\"  Age restrictions: {df_final['age_restriction'].notna().sum():,}\")\n",
    "print(f\"  Setting restrictions: {df_final['setting_restriction'].notna().sum():,}\")\n",
    "print(f\"  Exclusions: {df_final['exclusions'].notna().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT FINAL OUTPUT\n",
    "# =============================================================================\n",
    "\n",
    "OUTPUT_FILE = 'sk_tariffs_enriched.csv'\n",
    "\n",
    "df_export = df_final.copy()\n",
    "\n",
    "df_export['parent_code'] = df_export['parent_code'].apply(clean_tariff_code)\n",
    "df_export['add_on_to'] = df_export['add_on_to'].apply(clean_tariff_code_list)\n",
    "\n",
    "df_export['tariff_code'] = df_export['tariff_code'].apply(prefix_for_excel)\n",
    "df_export['specialty_code'] = df_export['specialty_code'].apply(\n",
    "    lambda x: prefix_for_excel(x) if pd.notna(x) and x != '' else x\n",
    ")\n",
    "\n",
    "df_export.to_csv(OUTPUT_FILE, index=False, encoding='utf-8')\n",
    "print(f\"✓ Saved {OUTPUT_FILE}\")\n",
    "\n",
    "clear_checkpoint()\n",
    "\n",
    "files.download(OUTPUT_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
