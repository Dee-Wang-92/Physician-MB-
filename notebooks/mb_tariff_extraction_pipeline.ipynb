{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b70YSpDzaUe"
      },
      "source": [
        "# Manitoba Tariff Extraction Pipeline\n",
        "\n",
        "**Phase 1**: Extract tariff codes with L1/L2/L3/L4 hierarchy  \n",
        "**Phase 2**: GPT enrichment for metadata extraction\n",
        "\n",
        "**Features:**\n",
        "- Extracts 4,600+ physician billing codes from Manitoba's Payment Schedule\n",
        "- Hierarchical categorization (Section → Category → Subcategory)\n",
        "- AI-powered enrichment: parent codes, add-ons, restrictions, exclusions\n",
        "- Checkpointing for crash recovery during long runs\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFKRBOEFzaUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b057a66-b230-4464-a417-23ae8413be1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Imports ready\n"
          ]
        }
      ],
      "source": [
        "!pip install openai -q\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "from typing import Optional, List, Tuple, Dict\n",
        "from openai import OpenAI\n",
        "from google.colab import files, userdata\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "print(\"✓ Imports ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgWlCdPazaUf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "bdd4633f-bbbd-44b8-e200-04c0d7ea9230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload the marked-up payment schedule text file (with L1/L2/L3 markers)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-914d0e2f-ef12-4fa5-8d07-1fdc81cda15b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-914d0e2f-ef12-4fa5-8d07-1fdc81cda15b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving mb_payment_schedule_marked (2).txt to mb_payment_schedule_marked (2).txt\n",
            "✓ 30,570 lines loaded\n"
          ]
        }
      ],
      "source": [
        "# Upload source file\n",
        "print(\"Upload the marked-up payment schedule text file (with L1/L2/L3 markers)\")\n",
        "uploaded = files.upload()\n",
        "SOURCE_FILE = list(uploaded.keys())[0]\n",
        "with open(SOURCE_FILE, 'r', encoding='utf-8') as f:\n",
        "    RAW_TEXT = f.read()\n",
        "LINES = RAW_TEXT.split('\\n')\n",
        "print(f\"✓ {len(LINES):,} lines loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEb2-2exzaUf"
      },
      "source": [
        "---\n",
        "## Configuration & Constants\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as3tqytGzaUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6160806-0190-4339-a1e2-33d81482c790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Configuration constants defined\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CONFIGURATION CONSTANTS\n",
        "# =============================================================================\n",
        "\n",
        "# Extraction settings\n",
        "CONTENT_START_MARKER = '«L1:RULESOFAPPLICATION»'\n",
        "CONTENT_START_MIN_LINE = 1000\n",
        "HIERARCHY_LOOKAHEAD_LINES = 5\n",
        "\n",
        "# Output settings\n",
        "MAX_DESCRIPTION_LENGTH = 500\n",
        "MAX_NOTES_LENGTH = 1000\n",
        "MAX_CONTEXT_LENGTH = 3500\n",
        "\n",
        "# GPT settings\n",
        "GPT_MODEL = \"gpt-5.2\"\n",
        "GPT_TEMPERATURE = 0\n",
        "API_CALL_DELAY_SECONDS = 0.1\n",
        "COST_PER_ENTRY_ESTIMATE = 0.005\n",
        "TIME_PER_ENTRY_SECONDS = 0.5\n",
        "\n",
        "# Progress reporting\n",
        "PROGRESS_REPORT_INTERVAL = 25\n",
        "\n",
        "# Checkpointing settings\n",
        "CHECKPOINT_INTERVAL = 100  # Save checkpoint every N entries\n",
        "CHECKPOINT_FILE = 'MB_phase2_checkpoint.json'\n",
        "\n",
        "# Fee parsing thresholds (for distinguishing unit values from fees)\n",
        "UNIT_VALUE_MIN = 19\n",
        "UNIT_VALUE_MAX = 28\n",
        "FEE_MIN_FOR_UNIT_DETECTION = 50\n",
        "\n",
        "# Section code mappings\n",
        "SECTION_PATTERNS = [\n",
        "    (r'visit|examination|internal medicine|general practice', 'A'),\n",
        "    (r'general schedule', 'B'),\n",
        "    (r'anesthesia', 'C'),\n",
        "    (r'integumentary|skin|breast', 'D'),\n",
        "    (r'musculoskeletal', 'E'),\n",
        "    (r'respiratory', 'F'),\n",
        "    (r'cardiovascular', 'G'),\n",
        "    (r'digestive', 'H'),\n",
        "    (r'urinary', 'I'),\n",
        "    (r'male genital', 'J'),\n",
        "    (r'female genital|obstetric|gyn', 'K'),\n",
        "    (r'maternity', 'L'),\n",
        "    (r'endocrine', 'M'),\n",
        "    (r'nervous', 'N'),\n",
        "    (r'eye|ocular|ophthal', 'O'),\n",
        "    (r'ear|otol', 'P'),\n",
        "    (r'nose|nasal|rhinol', 'Q'),\n",
        "    (r'diagnostic radiological', 'T'),\n",
        "    (r'nuclear medicine', 'U'),\n",
        "    (r'therapeutic radiological', 'V'),\n",
        "    (r'laboratory', 'W'),\n",
        "]\n",
        "\n",
        "# Add-on detection patterns\n",
        "ADD_ON_PATTERNS = [\n",
        "    r'\\badd\\b', r'\\badd-on\\b', r'\\badditional\\b', r'\\bsupplement\\b',\n",
        "    r'\\beach additional\\b', r'\\bper additional\\b', r'\\badd to\\b',\n",
        "]\n",
        "\n",
        "# Final output column order\n",
        "OUTPUT_COLUMNS = [\n",
        "    'tariff_code', 'tariff_code_display', 'parent_code',\n",
        "    'section_code', 'section_name', 'specialty_code', 'specialty_name',\n",
        "    'category', 'subcategory', 'subsubcategory',\n",
        "    'description', 'notes',\n",
        "    'fee_total', 'fee_technical', 'fee_professional', 'unit_value',\n",
        "    'is_add_on', 'add_on_to',\n",
        "    'age_restriction', 'setting_restriction', 'exclusions',\n",
        "    'is_provisional', 'is_asterisked', 'is_by_report',\n",
        "    'is_cross_reference', 'cross_reference_to',\n",
        "    'applicable_rules', 'time_requirement_minutes'\n",
        "]\n",
        "\n",
        "print(\"✓ Configuration constants defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "porwBgIQzaUg"
      },
      "source": [
        "---\n",
        "## Phase 1: Extraction with L1/L2/L3 Hierarchy\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vtfff66EzaUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e3d4c7-2509-42d3-9658-50ed5fc475ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Text cleaning utilities defined\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# TEXT CLEANING UTILITIES\n",
        "# =============================================================================\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"Normalize dashes and clean encoding issues.\"\"\"\n",
        "    text = text.replace('—', '-')\n",
        "    text = text.replace('–', '-')\n",
        "    text = text.replace('−', '-')\n",
        "    text = text.replace('‐', '-')\n",
        "    text = text.replace('\\u00a0', ' ')\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "def to_title_case(text: str) -> str:\n",
        "    \"\"\"Convert text to title case, handling special patterns.\"\"\"\n",
        "    if pd.isna(text) or not str(text).strip():\n",
        "        return text\n",
        "    text = str(text).strip()\n",
        "\n",
        "    # Handle 'O FFICE , H OME V ISITS' pattern (spaced first letters)\n",
        "    if re.match(r'^[A-Z]\\s+[A-Z]', text):\n",
        "        text = re.sub(r'\\b([A-Z])\\s+([A-Z]+)', r'\\1\\2', text)\n",
        "        text = re.sub(r'\\s*,\\s*', ', ', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    text = text.title()\n",
        "\n",
        "    # Preserve lowercase for small words\n",
        "    for word in ['And', 'Or', 'The', 'A', 'An', 'Of', 'In', 'For', 'To', 'By']:\n",
        "        text = re.sub(r'\\s' + word + r'\\s', ' ' + word.lower() + ' ', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "print(\"✓ Text cleaning utilities defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y974KtP7zaUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a036183f-b489-4d13-ba44-969034b40394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Section and specialty lookups defined\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# SECTION AND SPECIALTY LOOKUPS\n",
        "# =============================================================================\n",
        "\n",
        "def get_section_code(l1_text: str) -> str:\n",
        "    \"\"\"Map L1 section text to section code (A-W).\"\"\"\n",
        "    l1_lower = l1_text.lower()\n",
        "    for pattern, code in SECTION_PATTERNS:\n",
        "        if re.search(pattern, l1_lower):\n",
        "            return code\n",
        "    return ''\n",
        "\n",
        "\n",
        "def get_specialty_info(l1_text: str) -> Tuple[str, str]:\n",
        "    \"\"\"Extract specialty code and name from L1 text.\"\"\"\n",
        "    match = re.search(r'(.+?)\\s*\\((\\d{2}(?:-\\d+)?)\\)', l1_text)\n",
        "    if match:\n",
        "        name = match.group(1).strip()\n",
        "        name = re.sub(r'^Visits/Examinations[—–-]\\s*', '', name)\n",
        "        return match.group(2), name\n",
        "    return '', ''\n",
        "\n",
        "\n",
        "print(\"✓ Section and specialty lookups defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYYlcC2CzaUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0175d41e-7601-4c81-8ac1-61bf2ed45026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Fee and content extraction functions defined\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# FEE AND CONTENT EXTRACTION\n",
        "# =============================================================================\n",
        "\n",
        "def find_content_start(lines: List[str]) -> int:\n",
        "    \"\"\"Find the line where main content begins.\"\"\"\n",
        "    for i, line in enumerate(lines):\n",
        "        if CONTENT_START_MARKER in line and i > CONTENT_START_MIN_LINE:\n",
        "            return i\n",
        "    return 0\n",
        "\n",
        "\n",
        "def parse_fee(val: str) -> float:\n",
        "    \"\"\"Parse fee string, handling comma-separated thousands (e.g., '1,053.59').\"\"\"\n",
        "    return float(val.replace(',', ''))\n",
        "\n",
        "\n",
        "def extract_fee_from_block(block: str) -> dict:\n",
        "    \"\"\"Parse fee information from a code block.\"\"\"\n",
        "    result = {'fee': None, 'tec': None, 'pro': None, 'unit_value': None, 'is_by_report': False}\n",
        "\n",
        "    if re.search(r'By Report', block, re.IGNORECASE):\n",
        "        result['is_by_report'] = True\n",
        "\n",
        "    # Pattern for fees: handles comma-separated thousands (e.g., 1,053.59 or 112.42)\n",
        "    FEE_PATTERN = r'(\\d{1,3}(?:,\\d{3})*\\.\\d{2})'\n",
        "    UNIT_PATTERN = r'(\\d{2}\\.\\d{3})'\n",
        "\n",
        "    # Pattern: fee + unit value (e.g., \"...1,053.59  25.500\" or \"...112.42  21.375\")\n",
        "    match = re.search(r'\\.{3,}\\s*' + FEE_PATTERN + r'\\s+' + UNIT_PATTERN + r'\\s*$', block, re.MULTILINE)\n",
        "    if match:\n",
        "        result['fee'] = parse_fee(match.group(1))\n",
        "        result['unit_value'] = float(match.group(2))\n",
        "        return result\n",
        "\n",
        "    # Pattern: two decimal values (could be TEC/PRO or fee + unit)\n",
        "    match = re.search(r'\\.{3,}\\s*' + FEE_PATTERN + r'\\s+' + FEE_PATTERN + r'\\s*$', block, re.MULTILINE)\n",
        "    if match:\n",
        "        val1, val2 = parse_fee(match.group(1)), parse_fee(match.group(2))\n",
        "        if UNIT_VALUE_MIN < val2 < UNIT_VALUE_MAX and val1 > FEE_MIN_FOR_UNIT_DETECTION:\n",
        "            result['fee'] = val1\n",
        "            result['unit_value'] = val2\n",
        "        else:\n",
        "            result['tec'] = val1\n",
        "            result['pro'] = val2\n",
        "            result['fee'] = val1 + val2\n",
        "        return result\n",
        "\n",
        "    # Pattern: single fee (e.g., \"...1,053.59\" or \"...112.42\")\n",
        "    match = re.search(r'\\.{3,}\\s*' + FEE_PATTERN + r'\\s*$', block, re.MULTILINE)\n",
        "    if match:\n",
        "        result['fee'] = parse_fee(match.group(1))\n",
        "        return result\n",
        "\n",
        "    # Pattern: By Report with unit value\n",
        "    match = re.search(r'By Report.*?' + UNIT_PATTERN + r'\\s*$', block, re.MULTILINE | re.IGNORECASE)\n",
        "    if match:\n",
        "        result['unit_value'] = float(match.group(1))\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def extract_description(block: str, code: str) -> str:\n",
        "    \"\"\"Extract and clean description text from a code block.\"\"\"\n",
        "    text = re.sub(r'«CODE:~?\\d{4}\\*?»', '', block)\n",
        "    lines = []\n",
        "    for line in text.split('\\n'):\n",
        "        if re.match(r'^\\s*Notes?:', line, re.IGNORECASE):\n",
        "            break\n",
        "        if re.match(r'^\\s*April 1,|^[A-Z]-\\d+\\s*$|^\\f', line):\n",
        "            continue\n",
        "        if line.strip():\n",
        "            lines.append(line)\n",
        "    desc = ' '.join(lines)\n",
        "    desc = re.sub(r'^\\s*~?' + code + r'\\*?\\s*', '', desc)\n",
        "    desc = re.sub(r'\\s*\\.{3,}.*$', '', desc)\n",
        "    desc = re.sub(r'\\s*By Report.*$', '', desc, flags=re.IGNORECASE)\n",
        "    desc = clean_text(desc)\n",
        "    return desc\n",
        "\n",
        "\n",
        "def extract_notes(block: str) -> str:\n",
        "    \"\"\"Extract notes section from a code block.\"\"\"\n",
        "    match = re.search(r'Notes?:\\s*(.+?)(?=«|$)', block, re.DOTALL | re.IGNORECASE)\n",
        "    if match:\n",
        "        notes = clean_text(match.group(1))\n",
        "        return notes[:MAX_NOTES_LENGTH]\n",
        "    return ''\n",
        "\n",
        "\n",
        "def check_cross_reference(block: str) -> Tuple[bool, str]:\n",
        "    \"\"\"Check if block contains a cross-reference to another section.\"\"\"\n",
        "    patterns = [r'See (General Schedule|Section [A-Z])', r'-See ([A-Za-z ]+Schedule)']\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, block, re.IGNORECASE)\n",
        "        if match:\n",
        "            return True, match.group(1)\n",
        "    return False, ''\n",
        "\n",
        "\n",
        "def extract_rules(block: str) -> str:\n",
        "    \"\"\"Extract applicable rule references from a code block.\"\"\"\n",
        "    rules = set()\n",
        "    for match in re.finditer(r'Rules?\\s+(\\d+(?:\\s+to\\s+\\d+)?)', block, re.IGNORECASE):\n",
        "        rules.add(match.group(1))\n",
        "    return ', '.join(sorted(rules)) if rules else ''\n",
        "\n",
        "\n",
        "def extract_time_requirement(block: str) -> Optional[int]:\n",
        "    \"\"\"Extract minimum time requirement in minutes from a code block.\"\"\"\n",
        "    match = re.search(r'minimum of.*?(\\d+).*?minutes', block, re.IGNORECASE)\n",
        "    return int(match.group(1)) if match else None\n",
        "\n",
        "\n",
        "def is_add_on_fee(block: str, description: str) -> bool:\n",
        "    \"\"\"Detect if this is an add-on fee based on text patterns.\"\"\"\n",
        "    text = (block + ' ' + description).lower()\n",
        "    for pattern in ADD_ON_PATTERNS:\n",
        "        if re.search(pattern, text):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "print(\"✓ Fee and content extraction functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhWvMkEuzaUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "086ef695-7fcc-4e4c-f55a-740dd4d66c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Hierarchy extraction functions defined\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# HIERARCHY EXTRACTION\n",
        "# =============================================================================\n",
        "\n",
        "def extract_hierarchy_text(lines: List[str], start_idx: int, fallback_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract readable text for a hierarchy level marker.\n",
        "\n",
        "    Looks ahead from the marker line to find the first non-empty,\n",
        "    non-marker line and extracts the readable portion.\n",
        "\n",
        "    Args:\n",
        "        lines: All source lines\n",
        "        start_idx: Index of the hierarchy marker line\n",
        "        fallback_text: Text to use if no readable text found\n",
        "\n",
        "    Returns:\n",
        "        Cleaned readable text for this hierarchy level\n",
        "    \"\"\"\n",
        "    for k in range(start_idx + 1, min(start_idx + HIERARCHY_LOOKAHEAD_LINES, len(lines))):\n",
        "        next_line = lines[k].strip()\n",
        "        if next_line and not next_line.startswith('«') and not next_line.startswith('\\f'):\n",
        "            return clean_text(next_line.split('...')[0])\n",
        "    return clean_text(fallback_text)\n",
        "\n",
        "\n",
        "class HierarchyTracker:\n",
        "    \"\"\"\n",
        "    Tracks the current L1/L2/L3/L4 hierarchy state during extraction.\n",
        "\n",
        "    When a higher level is set, all lower levels are automatically reset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.l1 = \"\"\n",
        "        self.l2 = \"\"\n",
        "        self.l3 = \"\"\n",
        "        self.l4 = \"\"\n",
        "\n",
        "    def set_l1(self, value: str):\n",
        "        \"\"\"Set L1 and reset L2, L3, L4.\"\"\"\n",
        "        self.l1 = value\n",
        "        self.l2 = \"\"\n",
        "        self.l3 = \"\"\n",
        "        self.l4 = \"\"\n",
        "\n",
        "    def set_l2(self, value: str):\n",
        "        \"\"\"Set L2 and reset L3, L4.\"\"\"\n",
        "        self.l2 = value\n",
        "        self.l3 = \"\"\n",
        "        self.l4 = \"\"\n",
        "\n",
        "    def set_l3(self, value: str):\n",
        "        \"\"\"Set L3 and reset L4.\"\"\"\n",
        "        self.l3 = value\n",
        "        self.l4 = \"\"\n",
        "\n",
        "    def set_l4(self, value: str):\n",
        "        \"\"\"Set L4.\"\"\"\n",
        "        self.l4 = value\n",
        "\n",
        "    def get_current(self) -> Tuple[str, str, str, str]:\n",
        "        \"\"\"Return current hierarchy as tuple (l1, l2, l3, l4).\"\"\"\n",
        "        return self.l1, self.l2, self.l3, self.l4\n",
        "\n",
        "\n",
        "print(\"✓ Hierarchy extraction functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmckwBD5zaUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd644f3-f042-40a1-ddf4-ea96f7e2357e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Main extraction function defined\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# MAIN EXTRACTION FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def run_extraction(lines: List[str]) -> pd.DataFrame:\n",
        "    \"\"\"Main extraction function with L1/L2/L3/L4 hierarchy.\"\"\"\n",
        "    entries = []\n",
        "    start_idx = find_content_start(lines)\n",
        "    print(f\"Content starts at line {start_idx}\")\n",
        "\n",
        "    hierarchy = HierarchyTracker()\n",
        "\n",
        "    # Regex patterns for hierarchy and code markers\n",
        "    hierarchy_patterns = [\n",
        "        (r'«L1:(.+?)»', hierarchy.set_l1),\n",
        "        (r'«L2:(.+?)»', hierarchy.set_l2),\n",
        "        (r'«L3:(.+?)»', hierarchy.set_l3),\n",
        "        (r'«L4:(.+?)»', hierarchy.set_l4),\n",
        "    ]\n",
        "    code_pattern = re.compile(r'«CODE:(~)?(\\d{4})(\\*)?»')\n",
        "    block_end_pattern = re.compile(r'«CODE:|«L1:|«L2:|«L3:|«L4:')\n",
        "\n",
        "    i = start_idx\n",
        "    while i < len(lines):\n",
        "        line = lines[i]\n",
        "\n",
        "        # Check for hierarchy markers\n",
        "        hierarchy_matched = False\n",
        "        for pattern, setter in hierarchy_patterns:\n",
        "            match = re.search(pattern, line)\n",
        "            if match:\n",
        "                readable = extract_hierarchy_text(lines, i, match.group(1))\n",
        "                setter(readable)\n",
        "                hierarchy_matched = True\n",
        "                break\n",
        "\n",
        "        if hierarchy_matched:\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        # Check for CODE marker\n",
        "        code_match = code_pattern.search(line)\n",
        "        if code_match:\n",
        "            is_provisional_in_tag = code_match.group(1) is not None\n",
        "            code = code_match.group(2)\n",
        "            is_asterisked_in_tag = code_match.group(3) is not None\n",
        "            block_start = i\n",
        "\n",
        "            # Collect block lines until next marker\n",
        "            block_lines = [line]\n",
        "            j = i + 1\n",
        "            while j < len(lines):\n",
        "                next_line = lines[j]\n",
        "                if block_end_pattern.search(next_line):\n",
        "                    break\n",
        "                block_lines.append(next_line)\n",
        "                j += 1\n",
        "\n",
        "            block = '\\n'.join(block_lines)\n",
        "            fee_info = extract_fee_from_block(block)\n",
        "            is_xref, xref_to = check_cross_reference(block)\n",
        "\n",
        "            # Only include entries with fee, by-report, or cross-reference\n",
        "            if fee_info['fee'] is not None or fee_info['is_by_report'] or is_xref:\n",
        "                is_provisional = is_provisional_in_tag or bool(re.search(r'~\\s*' + code, block))\n",
        "                is_asterisked = is_asterisked_in_tag or bool(re.search(code + r'\\*', block))\n",
        "\n",
        "                l1, l2, l3, l4 = hierarchy.get_current()\n",
        "                section_code = get_section_code(l1)\n",
        "                specialty_code, specialty_name = get_specialty_info(l1)\n",
        "                description = extract_description(block, code)\n",
        "                code_padded = code.zfill(4)\n",
        "\n",
        "                display = code_padded\n",
        "                if is_provisional:\n",
        "                    display = '~' + display\n",
        "                if is_asterisked:\n",
        "                    display = display + '*'\n",
        "\n",
        "                entries.append({\n",
        "                    'tariff_code': code_padded,\n",
        "                    'tariff_code_display': display,\n",
        "                    'parent_code': None,\n",
        "                    'section_code': section_code,\n",
        "                    'section_name': l1,\n",
        "                    'specialty_code': specialty_code,\n",
        "                    'specialty_name': specialty_name,\n",
        "                    'category': l2,\n",
        "                    'subcategory': l3,\n",
        "                    'subsubcategory': l4,\n",
        "                    'description': description,\n",
        "                    'notes': extract_notes(block),\n",
        "                    'fee_total': fee_info['fee'],\n",
        "                    'fee_technical': fee_info['tec'],\n",
        "                    'fee_professional': fee_info['pro'],\n",
        "                    'unit_value': fee_info['unit_value'],\n",
        "                    'is_add_on': is_add_on_fee(block, description),\n",
        "                    'is_provisional': is_provisional,\n",
        "                    'is_asterisked': is_asterisked,\n",
        "                    'is_by_report': fee_info['is_by_report'],\n",
        "                    'is_cross_reference': is_xref,\n",
        "                    'cross_reference_to': xref_to,\n",
        "                    'applicable_rules': extract_rules(block),\n",
        "                    'time_requirement_minutes': extract_time_requirement(block),\n",
        "                    'source_line': block_start + 1,\n",
        "                })\n",
        "\n",
        "            i = j\n",
        "            continue\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    return pd.DataFrame(entries)\n",
        "\n",
        "\n",
        "print(\"✓ Main extraction function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94NxzRDPzaUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e478889d-4b63-4ca0-9bf0-b411c7b934f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 1: EXTRACTION\n",
            "============================================================\n",
            "Content starts at line 3382\n",
            "\n",
            "✓ Extracted 4,607 entries\n",
            "  Unique codes: 3,782\n",
            "  Has fee: 4,437 (96.3%)\n",
            "  By Report: 204\n",
            "  Add-on fees: 413\n",
            "\n",
            "Hierarchy coverage:\n",
            "  Has L1 (section_name): 4,607\n",
            "  Has L2 (category): 4,511\n",
            "  Has L3 (subcategory): 1,976\n",
            "  Has L4 (subsubcategory): 24\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# RUN PHASE 1 EXTRACTION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 1: EXTRACTION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "df = run_extraction(LINES)\n",
        "\n",
        "print(f\"\\n✓ Extracted {len(df):,} entries\")\n",
        "print(f\"  Unique codes: {df['tariff_code'].nunique():,}\")\n",
        "print(f\"  Has fee: {df['fee_total'].notna().sum():,} ({100*df['fee_total'].notna().sum()/len(df):.1f}%)\")\n",
        "print(f\"  By Report: {df['is_by_report'].sum():,}\")\n",
        "print(f\"  Add-on fees: {df['is_add_on'].sum():,}\")\n",
        "print(f\"\\nHierarchy coverage:\")\n",
        "print(f\"  Has L1 (section_name): {(df['section_name'] != '').sum():,}\")\n",
        "print(f\"  Has L2 (category): {(df['category'] != '').sum():,}\")\n",
        "print(f\"  Has L3 (subcategory): {(df['subcategory'] != '').sum():,}\")\n",
        "print(f\"  Has L4 (subsubcategory): {(df['subsubcategory'] != '').sum():,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSOiOu9YzaUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f5b56b-a498-4d35-c623-d2a24f01a454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample hierarchy:\n",
            "\n",
            "0171:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Investigation\n",
            "  Desc: Biopsy of skin, subcutaneous tissue or m\n",
            "\n",
            "0172:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Investigation\n",
            "  Desc: Dermatoscopy\n",
            "\n",
            "0415:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Investigation\n",
            "  Desc: Woods light examination\n",
            "\n",
            "0106:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: Abscess or hematoma, puncture aspiration\n",
            "\n",
            "0103:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: Carbuncle drainage\n",
            "\n",
            "0101:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: Superficial localized infection such as \n",
            "\n",
            "0170:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: Acne Surgery-Marsupialization, opening o\n",
            "\n",
            "0130:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: Foreign body subcutaneous tissue, remova\n",
            "\n",
            "0256:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: removal, complicated\n",
            "\n",
            "0125:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: Laser treatment of port wine stains and \n",
            "\n",
            "0128:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: Pulsed dye laser, first square inch (6.2\n",
            "\n",
            "0129:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: each additional square inch or portion t\n",
            "\n",
            "0394:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: Laser vaporization-face-one (1) lesion\n",
            "\n",
            "0395:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: two (2) lesions\n",
            "\n",
            "0396:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: three (3) or more lesions\n",
            "\n",
            "0397:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: Elsewhere-one (1) lesion\n",
            "\n",
            "0398:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: two (2) lesions\n",
            "\n",
            "0399:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: three (3) or more lesions\n",
            "\n",
            "0428:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Incision\n",
            "  Desc: Reconstructive laser depilation, per squ\n",
            "\n",
            "0251:\n",
            "  L1: Integumentary System\n",
            "  L2: Cutaneous Procedures\n",
            "  L3: Revision and Repair\n",
            "  Desc: Wound repair (local anesthetic included)\n"
          ]
        }
      ],
      "source": [
        "# Show hierarchy examples\n",
        "print(\"Sample hierarchy:\")\n",
        "sample = df[df['subcategory'] != ''].head(20)\n",
        "for idx, row in sample.iterrows():\n",
        "    print(f\"\\n{row['tariff_code']}:\")\n",
        "    print(f\"  L1: {row['section_name'][:40]}\")\n",
        "    print(f\"  L2: {row['category'][:40] if row['category'] else '(none)'}\")\n",
        "    print(f\"  L3: {row['subcategory'][:40] if row['subcategory'] else '(none)'}\")\n",
        "    print(f\"  Desc: {row['description'][:40]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9BP3cNTzaUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a02ffdb0-3fda-4ef1-852d-b58f8b5936c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Known code validation:\n",
            "  8540: 112.42 -> ✓\n",
            "  8550: 184.96 -> ✓\n",
            "  8403: 59.05 -> ✓\n",
            "  8563: NOT FOUND\n",
            "  0770: 518.14 -> ✓\n"
          ]
        }
      ],
      "source": [
        "# Validate known codes\n",
        "print(\"\\nKnown code validation:\")\n",
        "KNOWN_CODES = [\n",
        "    ('8540', 112.42),\n",
        "    ('8550', 184.96),\n",
        "    ('8403', 59.05),\n",
        "    ('8563', 54.86),\n",
        "    ('0770', 518.14),\n",
        "]\n",
        "\n",
        "for code, expected_fee in KNOWN_CODES:\n",
        "    matches = df[df['tariff_code'] == code]\n",
        "    if len(matches) > 0:\n",
        "        actual = matches.iloc[0]['fee_total']\n",
        "        status = '✓' if abs(actual - expected_fee) < 0.01 else f'✗ got {actual}'\n",
        "        print(f\"  {code}: {expected_fee} -> {status}\")\n",
        "    else:\n",
        "        print(f\"  {code}: NOT FOUND\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfKdFMM-zaUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8baaf347-ac48-43a1-fbe2-04d0c034f44b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Data cleaning applied (title case)\n",
            "\n",
            "Sample cleaned data:\n",
            "  8561: (none) > For Special Calls Made to a Pa\n",
            "  8598: (none) > For Special Calls Made to the \n",
            "  8566: (none) > For Special Calls Made in Obst\n",
            "  8567: (none) > For Special Calls Made in Non-\n",
            "  8645: Office , Home Visits > Extended Complete History and \n",
            "  8540: Office , Home Visits > Complete History and Physical \n",
            "  8646: Office , Home Visits > Extended Complete or Extensive\n",
            "  8502: Office , Home Visits > Complete or Extensive Re-Exami\n",
            "  8647: Office , Home Visits > Extended Regional History & Ex\n",
            "  8403: Office , Home Visits > Regional History and Examinati\n"
          ]
        }
      ],
      "source": [
        "# Apply title case cleaning to text columns\n",
        "TEXT_COLUMNS = ['section_name', 'category', 'subcategory', 'subsubcategory', 'description']\n",
        "\n",
        "for col in TEXT_COLUMNS:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].apply(to_title_case)\n",
        "\n",
        "print(\"✓ Data cleaning applied (title case)\")\n",
        "print(f\"\\nSample cleaned data:\")\n",
        "sample = df[['tariff_code', 'section_name', 'category', 'subcategory', 'description']].head(10)\n",
        "for idx, row in sample.iterrows():\n",
        "    category_display = row['category'][:30] if row['category'] else '(none)'\n",
        "    print(f\"  {row['tariff_code']}: {category_display} > {row['description'][:30]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wmV--zizaUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286fea78-09cd-47f0-cc84-5d0db8cc7240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Export utilities defined\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# EXPORT UTILITIES\n",
        "# =============================================================================\n",
        "\n",
        "def prefix_for_excel(value, prefix=\"'\"):\n",
        "    \"\"\"Prefix a value to prevent Excel auto-formatting (e.g., dropping leading zeros).\"\"\"\n",
        "    if pd.isna(value) or value == '' or value is None:\n",
        "        return value\n",
        "    return f\"{prefix}{value}\"\n",
        "\n",
        "\n",
        "def clean_tariff_code(x):\n",
        "    \"\"\"Clean and format a single tariff code (4 digits, no .0).\"\"\"\n",
        "    if pd.isna(x) or x == '' or x is None:\n",
        "        return None\n",
        "    return str(x).replace('.0', '').strip().zfill(4)\n",
        "\n",
        "\n",
        "def clean_tariff_code_list(x):\n",
        "    \"\"\"Clean and format a comma-separated list of tariff codes.\"\"\"\n",
        "    if pd.isna(x) or x == '' or x is None:\n",
        "        return None\n",
        "    codes = [c.strip().replace('.0', '').zfill(4) for c in str(x).split(',')]\n",
        "    return ', '.join(codes)\n",
        "\n",
        "\n",
        "print(\"✓ Export utilities defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb_febrbzaUh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "19b5bad7-072a-4b8f-ce94-5b6213ed7674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Phase 1 export saved: mb_tariffs_phase1.csv\n",
            "  4607 rows, 25 columns\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5d27ac10-c951-4ca3-a61a-a86682da24bf\", \"mb_tariffs_phase1.csv\", 1087004)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Export Phase 1 output\n",
        "PHASE1_FILE = 'mb_tariffs_phase1.csv'\n",
        "\n",
        "df_phase1 = df.copy()\n",
        "df_phase1['tariff_code'] = df_phase1['tariff_code'].apply(lambda x: prefix_for_excel(x))\n",
        "df_phase1['specialty_code'] = df_phase1['specialty_code'].apply(\n",
        "    lambda x: prefix_for_excel(x) if x != '' else x\n",
        ")\n",
        "\n",
        "df_phase1.to_csv(PHASE1_FILE, index=False, encoding='utf-8')\n",
        "print(f\"✓ Phase 1 export saved: {PHASE1_FILE}\")\n",
        "print(f\"  {len(df)} rows, {len(df.columns)} columns\")\n",
        "files.download(PHASE1_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTVuCDorzaUh"
      },
      "source": [
        "---\n",
        "## Phase 2: GPT Full Review\n",
        "\n",
        "GPT reviews ALL entries for:\n",
        "- Description completion (if L1+L2+L3+L4+desc insufficient)\n",
        "- Parent code relationships\n",
        "- Add-on fee detection (is_add_on, add_on_to)\n",
        "- Age restrictions\n",
        "- Setting restrictions\n",
        "- Exclusions\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJOO8pMkzaUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f92953e9-a498-40bc-c3be-fedba91b59b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter OpenAI API key (input hidden): ··········\n",
            "✓ API key entered\n",
            "✓ OpenAI client ready\n"
          ]
        }
      ],
      "source": [
        "# Setup OpenAI (secure API key input - key will NOT be displayed)\n",
        "try:\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    print(\"✓ API key loaded from Colab secrets\")\n",
        "except:\n",
        "    OPENAI_API_KEY = getpass.getpass(\"Enter OpenAI API key (input hidden): \")\n",
        "    print(\"✓ API key entered\")\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "print(\"✓ OpenAI client ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHK849mczaUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "238b91ed-0ca4-4042-bd3c-8620a0a5c2c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total entries to review: 4607\n",
            "Estimated cost: ~$23.04\n",
            "Estimated time: ~38 minutes\n"
          ]
        }
      ],
      "source": [
        "# Phase 2 cost and time estimates\n",
        "total_entries = len(df)\n",
        "estimated_cost = total_entries * COST_PER_ENTRY_ESTIMATE\n",
        "estimated_minutes = total_entries * TIME_PER_ENTRY_SECONDS / 60\n",
        "\n",
        "print(f\"Total entries to review: {total_entries}\")\n",
        "print(f\"Estimated cost: ~${estimated_cost:.2f}\")\n",
        "print(f\"Estimated time: ~{estimated_minutes:.0f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZkFFt4jzaUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b87abd-316e-4960-d20f-75729e8b6c06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ System prompt defined\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# GPT REVIEW SYSTEM PROMPT\n",
        "# =============================================================================\n",
        "\n",
        "SYSTEM_PROMPT = '''You are an expert medical billing coder reviewing Manitoba's Physician's Manual.\n",
        "\n",
        "For EACH code, extract the following:\n",
        "\n",
        "═══════════════════════════════════════════════════════════════\n",
        "1. DESCRIPTION COMPLETION\n",
        "═══════════════════════════════════════════════════════════════\n",
        "IMPORTANT: L1, L2, L3, L4 are ALREADY stored in separate columns.\n",
        "Do NOT repeat them in the description.\n",
        "\n",
        "If a description seems incomplete (e.g., \"open reduction\", \"and left heart cath\"):\n",
        "- Set parent_code to link it to its parent\n",
        "- KEEP the description SHORT as-is - the parent_code provides context\n",
        "- Users can follow the parent_code chain to get full meaning\n",
        "\n",
        "ONLY expand a description if there is NO parent AND it is truly ambiguous alone.\n",
        "Set needs_completion=false in most cases. Keep original descriptions.\n",
        "\n",
        "═══════════════════════════════════════════════════════════════\n",
        "2. PARENT_CODE\n",
        "═══════════════════════════════════════════════════════════════\n",
        "\n",
        "WHY THIS MATTERS:\n",
        "This dataset must be usable standalone. Every row must make sense on its own.\n",
        "Right now, \"Open Reduction\" appears dozens of times with no body part.\n",
        "That's useless - open reduction of WHAT? We need parent_code to link related\n",
        "procedures so users can understand what each code actually means.\n",
        "\n",
        "WHAT IS A CHILD CODE:\n",
        "A child code is a code whose description is incomplete on its own.\n",
        "The Manitoba manual uses INDENTATION to avoid repeating anatomy.\n",
        "\"Open reduction\" indented under \"Femur, neck\" means femur neck open reduction.\n",
        "The child inherits meaning from its parent.\n",
        "\n",
        "HOW TO IDENTIFY CHILD CODES:\n",
        "Look at the WHITESPACE before descriptions in the source context.\n",
        "More indentation = child of something above it.\n",
        "The parent is the FIRST preceding code with LESS indentation - then STOP.\n",
        "\n",
        "SET parent_code TO THE IMMEDIATE PARENT:\n",
        "    0865    Femur, neck, closed reduction              → parent_code: null\n",
        "    0868       open reduction                          → parent_code: \"0865\"\n",
        "    0870          prosthetic replacement               → parent_code: \"0868\"\n",
        "    0877       slipped upper femoral epiphysis         → parent_code: \"0865\"\n",
        "    0872       intertrochanteric, closed reduction     → parent_code: \"0865\"\n",
        "    0874          open reduction                       → parent_code: \"0872\"\n",
        "\n",
        "Notice: 0877 and 0872 return to the SAME indentation level as 0868, so they\n",
        "share the same parent (0865). 0874 is indented under 0872, so its parent is 0872.\n",
        "\n",
        "This creates a chain: grandchild → child → parent. For example:\n",
        "- 0870's full meaning: Femur neck → open reduction → prosthetic replacement\n",
        "- 0874's full meaning: Femur → intertrochanteric → open reduction\n",
        "\n",
        "CRITICAL - STOP AT FIRST MATCH:\n",
        "    3872    Percutaneous nephrostomy...                → parent_code: null\n",
        "    3873    Single stone removal without lithotripsy   → parent_code: null (same level)\n",
        "    3875       plus nephrostomy...                     → parent_code: \"3873\"\n",
        "    3878       with electrohydraulic lithotripsy...    → parent_code: \"3873\" (NOT 3872!)\n",
        "    3879          plus nephrostomy...                  → parent_code: \"3878\"\n",
        "\n",
        "For 3878: scan backwards, skip 3875 (more indent), hit 3873 (less indent) → STOP.\n",
        "Do NOT continue back to 3872 even though it has the same indent as 3873.\n",
        "\n",
        "ALSO USE parent_code FOR TIERED/VARIANT CODES:\n",
        "- \"Day 2-10, per day\" → parent is \"Day 1\" code\n",
        "- \"Each additional 15 minutes\" → parent is base time code\n",
        "- Level B care → parent is Level A code\n",
        "- Any tiered/variant where you pick ONE based on situation\n",
        "\n",
        "The parent_code must be a 4-digit code VISIBLE in the nearby context.\n",
        "\n",
        "═══════════════════════════════════════════════════════════════\n",
        "3. ADD-ON DETECTION (for SUPPLEMENTS - billed TOGETHER)\n",
        "═══════════════════════════════════════════════════════════════\n",
        "is_add_on = true ONLY when THIS CODE is explicitly a supplement\n",
        "that gets billed ON TOP OF another service.\n",
        "\n",
        "THE \", ADD\" RULE - MOST IMPORTANT:\n",
        "If the description ends with \", Add\" → this is an ADD-ON, not a child code.\n",
        "Set is_add_on=true and parent_code=null.\n",
        "Examples: \"Intracoronary Drug Injection, Add\" → is_add_on=true, parent_code=null\n",
        "          \"Coronary Thrombectomy, Add\" → is_add_on=true, parent_code=null\n",
        "\n",
        "DEFINITE ADD-ONS (is_add_on: true):\n",
        "- Description ends with \", Add\" or \", add\" ← THIS IS THE KEY INDICATOR\n",
        "- Description contains \"supplement add to\" or \"add to [X] fee\"\n",
        "- Code is a percentage fee (20%, 25%) added to another service\n",
        "- Notes say THIS code \"may be claimed in addition to\" other codes\n",
        "- Special Call fees (8561, 8598, 8566, 8567, 8563) - these are add-ons\n",
        "\n",
        "NOT ADD-ONS (is_add_on: false):\n",
        "- \"premium will be applied to tariffs X, Y, Z\" - this describes a MODIFIER, not an add-on code\n",
        "- Lists of tariff codes that receive a premium - the listed codes are NOT add-ons\n",
        "- Regular examination/visit codes (8540, 8550, 8645, etc.)\n",
        "- \"Each additional X\" patterns - these are VARIANTS, use parent_code instead\n",
        "- Codes where OTHER things can be claimed with them - that doesn't make THIS code an add-on\n",
        "\n",
        "CRITICAL DISTINCTION:\n",
        "- \"8700 supplement add to visit fee\" → 8700 IS an add-on\n",
        "- \"premium applied to 8540 in hospital\" → 8540 is NOT an add-on (it receives a premium)\n",
        "\n",
        "add_on_to: Only fill if specific codes are stated that THIS code adds to.\n",
        "Leave null if it says generic \"visit fee\" or \"surgical fee\".\n",
        "\n",
        "═══════════════════════════════════════════════════════════════\n",
        "4. AGE RESTRICTION (only if EXPLICITLY stated)\n",
        "═══════════════════════════════════════════════════════════════\n",
        "Look for explicit age requirements in the notes:\n",
        "- \"under 18\", \"under eighteen\", \"child\", \"pediatric\"\n",
        "- \"over 65\", \"elderly\"\n",
        "- \"newborn\", \"infant\", \"neonate\"\n",
        "\n",
        "Return the exact restriction text. null if not mentioned.\n",
        "\n",
        "═══════════════════════════════════════════════════════════════\n",
        "5. SETTING RESTRICTION (only if EXPLICITLY stated)\n",
        "═══════════════════════════════════════════════════════════════\n",
        "Look for explicit setting requirements:\n",
        "- \"hospital only\", \"hospital in-patient\"\n",
        "- \"office\", \"home\"\n",
        "- \"ICU\", \"NICU\", \"PICU\"\n",
        "- \"Emergency Department\"\n",
        "\n",
        "Return the exact restriction text. null if not mentioned.\n",
        "\n",
        "═══════════════════════════════════════════════════════════════\n",
        "6. EXCLUSIONS (only if EXPLICITLY stated)\n",
        "═══════════════════════════════════════════════════════════════\n",
        "Look for explicit billing exclusions:\n",
        "- \"cannot be claimed with\", \"may not be claimed with\"\n",
        "- \"not claimable with\", \"excludes\"\n",
        "- \"does not include\"\n",
        "\n",
        "Return the exact exclusion text. null if not mentioned.\n",
        "\n",
        "═══════════════════════════════════════════════════════════════\n",
        "CRITICAL RULES\n",
        "═══════════════════════════════════════════════════════════════\n",
        "1. Do NOT invent data. Only extract what is EXPLICITLY stated or clearly visible.\n",
        "\n",
        "2. \", ADD\" SUFFIX = ADD-ON (MUTUALLY EXCLUSIVE WITH PARENT_CODE):\n",
        "   If description ends with \", Add\" → is_add_on=true, parent_code=null\n",
        "   These are NEVER child codes. They are billed ON TOP OF other procedures.\n",
        "\n",
        "3. INDENTED = CHILD CODE (uses parent_code, NOT is_add_on):\n",
        "   If code is indented under another → parent_code=that code, is_add_on=false\n",
        "   These inherit context from their parent.\n",
        "\n",
        "4. VARIANT = CHILD CODE (uses parent_code):\n",
        "   \"Day 2-10\" under \"Day 1\" → parent_code links them, is_add_on=false\n",
        "   You pick ONE based on situation, not both.\n",
        "\n",
        "5. Do NOT expand descriptions with L1/L2/L3 - those are in separate columns.\n",
        "   Keep descriptions short. The parent_code chain provides context.\n",
        "\n",
        "6. When you see a list of tariff codes in context, do NOT assume they are\n",
        "   related to the current code unless explicitly stated.\n",
        "\n",
        "7. \"Premium applied to X\" means X receives a premium, NOT that X is an add-on.\n",
        "\n",
        "8. READ THE INDENTATION CAREFULLY. This is how the manual groups related procedures.\n",
        "\n",
        "Return JSON:\n",
        "{\n",
        "  \"needs_completion\": true/false,\n",
        "  \"description\": \"...\",\n",
        "  \"parent_code\": \"XXXX\" or null,\n",
        "  \"is_add_on\": true/false,\n",
        "  \"add_on_to\": \"XXXX, YYYY\" or null,\n",
        "  \"age_restriction\": \"...\" or null,\n",
        "  \"setting_restriction\": \"...\" or null,\n",
        "  \"exclusions\": \"...\" or null\n",
        "}\n",
        "'''\n",
        "\n",
        "print(\"✓ System prompt defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PBiAvrczaUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed58e59-04d7-4396-c97e-3618458a34a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ GPT evaluation functions defined\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# GPT EVALUATION FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def get_source_context(source_line: int, lines: List[str], before: int = 30, after: int = 5) -> str:\n",
        "    \"\"\"Get surrounding context from source file for GPT review.\"\"\"\n",
        "    if pd.isna(source_line) or source_line < 1:\n",
        "        return \"(no source context available)\"\n",
        "    source_line = int(source_line)\n",
        "    start = max(0, source_line - before - 1)\n",
        "    end = min(len(lines), source_line + after)\n",
        "    context = '\\n'.join(lines[start:end])\n",
        "    context = context.replace('\\f', '\\n').strip()\n",
        "    return context[:MAX_CONTEXT_LENGTH]\n",
        "\n",
        "\n",
        "def build_user_message(row: pd.Series, context: str) -> str:\n",
        "    \"\"\"Build the user message for GPT review.\"\"\"\n",
        "    return f\"\"\"Code: {row['tariff_code']}\n",
        "\n",
        "HIERARCHY:\n",
        "  L1 (section): {row['section_name']}\n",
        "  L2 (category): {row['category'] if row['category'] else '(none)'}\n",
        "  L3 (subcategory): {row['subcategory'] if row['subcategory'] else '(none)'}\n",
        "  L4 (subsubcategory): {row['subsubcategory'] if row['subsubcategory'] else '(none)'}\n",
        "\n",
        "Description: \"{row['description']}\"\n",
        "Notes: \"{row['notes'] if row['notes'] else '(none)'}\"\n",
        "\n",
        "Source context:\n",
        "```\n",
        "{context}\n",
        "```\"\"\"\n",
        "\n",
        "\n",
        "def parse_gpt_response(result: Dict, original_description: str) -> Dict:\n",
        "    \"\"\"Parse and clean GPT response.\"\"\"\n",
        "    # Clean description\n",
        "    desc = result.get('description', original_description)\n",
        "    desc = clean_text(desc)\n",
        "    if len(desc) > MAX_DESCRIPTION_LENGTH:\n",
        "        desc = desc[:MAX_DESCRIPTION_LENGTH - 3] + '...'\n",
        "\n",
        "    # Clean parent_code\n",
        "    parent = result.get('parent_code')\n",
        "    if parent:\n",
        "        parent = str(parent).replace('.0', '').strip().zfill(4)\n",
        "        if not re.match(r'^\\d{4}$', parent):\n",
        "            parent = None\n",
        "\n",
        "    # Clean add_on_to (can be single code or comma-separated list)\n",
        "    add_on_to = result.get('add_on_to')\n",
        "    if add_on_to:\n",
        "        add_on_to = str(add_on_to).strip()\n",
        "        codes = [c.strip().replace('.0', '').zfill(4) for c in add_on_to.split(',')]\n",
        "        codes = [c for c in codes if re.match(r'^\\d{4}$', c)]\n",
        "        add_on_to = ', '.join(codes) if codes else None\n",
        "\n",
        "    return {\n",
        "        'needs_completion': result.get('needs_completion', False),\n",
        "        'description': desc,\n",
        "        'parent_code': parent,\n",
        "        'is_add_on': result.get('is_add_on', False),\n",
        "        'add_on_to': add_on_to,\n",
        "        'age_restriction': result.get('age_restriction'),\n",
        "        'setting_restriction': result.get('setting_restriction'),\n",
        "        'exclusions': result.get('exclusions')\n",
        "    }\n",
        "\n",
        "\n",
        "def get_empty_result(original_description: str) -> Dict:\n",
        "    \"\"\"Return empty result for error cases.\"\"\"\n",
        "    return {\n",
        "        'needs_completion': False,\n",
        "        'description': original_description,\n",
        "        'parent_code': None,\n",
        "        'is_add_on': False,\n",
        "        'add_on_to': None,\n",
        "        'age_restriction': None,\n",
        "        'setting_restriction': None,\n",
        "        'exclusions': None\n",
        "    }\n",
        "\n",
        "\n",
        "def evaluate_entry(row: pd.Series, lines: List[str]) -> Dict:\n",
        "    \"\"\"Send entry to GPT for full evaluation.\"\"\"\n",
        "    context = get_source_context(row['source_line'], lines)\n",
        "    user_msg = build_user_message(row, context)\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=GPT_MODEL,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": user_msg}\n",
        "            ],\n",
        "            temperature=GPT_TEMPERATURE,\n",
        "            response_format={\"type\": \"json_object\"}\n",
        "        )\n",
        "        result = json.loads(response.choices[0].message.content)\n",
        "        return parse_gpt_response(result, row['description'])\n",
        "    except Exception as e:\n",
        "        print(f\"  Error on {row['tariff_code']}: {e}\")\n",
        "        return get_empty_result(row['description'])\n",
        "\n",
        "\n",
        "print(\"✓ GPT evaluation functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEZQ8nn_zaUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f98bb2-7262-4312-8acf-34a0cd2beb52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Checkpointing functions defined\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CHECKPOINTING FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def save_checkpoint(results: Dict, stats: Dict, last_processed_idx: int, checkpoint_file: str = CHECKPOINT_FILE):\n",
        "    \"\"\"Save current progress to a checkpoint file.\"\"\"\n",
        "    checkpoint_data = {\n",
        "        'results': {str(k): v for k, v in results.items()},  # Convert keys to strings for JSON\n",
        "        'stats': stats,\n",
        "        'last_processed_idx': last_processed_idx,\n",
        "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "    }\n",
        "    with open(checkpoint_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(checkpoint_data, f, indent=2)\n",
        "    print(f\"  [Checkpoint saved: {last_processed_idx + 1} entries]\")\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_file: str = CHECKPOINT_FILE) -> Tuple[Dict, Dict, int]:\n",
        "    \"\"\"Load progress from a checkpoint file if it exists.\"\"\"\n",
        "    if not os.path.exists(checkpoint_file):\n",
        "        return {}, {'completed': 0, 'parents': 0, 'add_ons': 0, 'age_restricted': 0, 'setting_restricted': 0, 'has_exclusions': 0}, -1\n",
        "\n",
        "    try:\n",
        "        with open(checkpoint_file, 'r', encoding='utf-8') as f:\n",
        "            checkpoint_data = json.load(f)\n",
        "\n",
        "        # Convert string keys back to integers\n",
        "        results = {int(k): v for k, v in checkpoint_data['results'].items()}\n",
        "        stats = checkpoint_data['stats']\n",
        "        last_processed_idx = checkpoint_data['last_processed_idx']\n",
        "\n",
        "        print(f\"✓ Loaded checkpoint from {checkpoint_data['timestamp']}\")\n",
        "        print(f\"  Resuming from entry {last_processed_idx + 1}\")\n",
        "        print(f\"  Stats so far: completions={stats['completed']}, parents={stats['parents']}, add-ons={stats['add_ons']}\")\n",
        "\n",
        "        return results, stats, last_processed_idx\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not load checkpoint ({e}). Starting fresh.\")\n",
        "        return {}, {'completed': 0, 'parents': 0, 'add_ons': 0, 'age_restricted': 0, 'setting_restricted': 0, 'has_exclusions': 0}, -1\n",
        "\n",
        "\n",
        "def clear_checkpoint(checkpoint_file: str = CHECKPOINT_FILE):\n",
        "    \"\"\"Remove checkpoint file after successful completion.\"\"\"\n",
        "    if os.path.exists(checkpoint_file):\n",
        "        os.remove(checkpoint_file)\n",
        "        print(f\"✓ Checkpoint file removed\")\n",
        "\n",
        "\n",
        "print(\"✓ Checkpointing functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PvPGPIrzaUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73283d8a-5e26-4c52-d5ec-207ca8fac53a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL RUN: Processing all 4607 entries\n",
            "\n",
            "Estimated time: ~38.4 minutes\n",
            "Estimated cost: ~$23.04\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# TEST CONFIGURATION\n",
        "# =============================================================================\n",
        "# Set TEST_MODE = True to test on a subset of codes\n",
        "# Use the filters below to target specific sections for testing\n",
        "\n",
        "TEST_MODE = False  # Set to False for full run\n",
        "\n",
        "# --- FILTER OPTIONS (only used when TEST_MODE = True) ---\n",
        "\n",
        "# Option 1: Filter by L2 category (e.g., \"Lower Extremity\", \"Upper Extremity\")\n",
        "TEST_CATEGORY = None  # Set to None to disable\n",
        "\n",
        "# Option 2: Filter by L1 section name (partial match)\n",
        "TEST_SECTION = None  # e.g., \"Musculoskeletal\" - Set to None to disable\n",
        "\n",
        "# Option 3: Filter by tariff code range\n",
        "TEST_CODE_START = None  # e.g., \"0865\" - Set to None to disable\n",
        "TEST_CODE_END = None    # e.g., \"0930\" - Set to None to disable\n",
        "\n",
        "# Option 4: Filter by specific codes (list)\n",
        "TEST_CODES = None  # e.g., [\"0865\", \"0868\", \"0870\", \"0872\", \"0874\"] - Set to None to disable\n",
        "\n",
        "# Option 5: Just take first N entries (fallback)\n",
        "TEST_LIMIT = 50\n",
        "\n",
        "# --- BUILD TEST DATAFRAME ---\n",
        "\n",
        "if TEST_MODE:\n",
        "    process_df = df.copy()\n",
        "    filter_applied = False\n",
        "\n",
        "    # Apply category filter\n",
        "    if TEST_CATEGORY:\n",
        "        process_df = process_df[process_df['category'].str.contains(TEST_CATEGORY, case=False, na=False)]\n",
        "        print(f\"✓ Filtered by category '{TEST_CATEGORY}': {len(process_df)} entries\")\n",
        "        filter_applied = True\n",
        "\n",
        "    # Apply section filter\n",
        "    elif TEST_SECTION:\n",
        "        process_df = process_df[process_df['section_name'].str.contains(TEST_SECTION, case=False, na=False)]\n",
        "        print(f\"✓ Filtered by section '{TEST_SECTION}': {len(process_df)} entries\")\n",
        "        filter_applied = True\n",
        "\n",
        "    # Apply code range filter\n",
        "    elif TEST_CODE_START and TEST_CODE_END:\n",
        "        process_df = process_df[(process_df['tariff_code'] >= TEST_CODE_START) &\n",
        "                                 (process_df['tariff_code'] <= TEST_CODE_END)]\n",
        "        print(f\"✓ Filtered by code range {TEST_CODE_START}-{TEST_CODE_END}: {len(process_df)} entries\")\n",
        "        filter_applied = True\n",
        "\n",
        "    # Apply specific codes filter\n",
        "    elif TEST_CODES:\n",
        "        process_df = process_df[process_df['tariff_code'].isin(TEST_CODES)]\n",
        "        print(f\"✓ Filtered by specific codes {TEST_CODES}: {len(process_df)} entries\")\n",
        "        filter_applied = True\n",
        "\n",
        "    # Fallback to limit\n",
        "    if not filter_applied or len(process_df) == 0:\n",
        "        process_df = df.head(TEST_LIMIT).copy()\n",
        "        print(f\"✓ TEST MODE: First {len(process_df)} entries\")\n",
        "\n",
        "    # Show what we're testing\n",
        "    print(f\"\\nCodes to process:\")\n",
        "    for idx, row in process_df.head(20).iterrows():\n",
        "        print(f\"  {row['tariff_code']}: {row['description'][:50]}\")\n",
        "    if len(process_df) > 20:\n",
        "        print(f\"  ... and {len(process_df) - 20} more\")\n",
        "else:\n",
        "    process_df = df.copy()\n",
        "    print(f\"FULL RUN: Processing all {len(process_df)} entries\")\n",
        "\n",
        "print(f\"\\nEstimated time: ~{len(process_df) * TIME_PER_ENTRY_SECONDS / 60:.1f} minutes\")\n",
        "print(f\"Estimated cost: ~${len(process_df) * COST_PER_ENTRY_ESTIMATE:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coatyDBGzaUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86adfc4f-46ab-4735-ac6d-2b70be2dfb40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PHASE 2: GPT FULL REVIEW\n",
            "============================================================\n",
            "\n",
            "✓ Loaded checkpoint from 2026-01-28 23:37:08\n",
            "  Resuming from entry 4607\n",
            "  Stats so far: completions=1, parents=928, add-ons=322\n",
            "Skipping 4607 already-processed entries...\n",
            "  [Checkpoint saved: 4607 entries]\n",
            "\n",
            "✓ Phase 2 complete!\n",
            "  Descriptions completed: 1\n",
            "  Parent codes: 928\n",
            "  Add-on fees: 322\n",
            "  Age restricted: 162\n",
            "  Setting restricted: 169\n",
            "  Has exclusions: 386\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# RUN PHASE 2 GPT REVIEW (with checkpointing)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PHASE 2: GPT FULL REVIEW\")\n",
        "print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "# Load checkpoint if exists (allows resuming after crash)\n",
        "results, stats, last_processed_idx = load_checkpoint()\n",
        "\n",
        "# Build list of (position, index, row) to process\n",
        "entries_to_process = list(enumerate(process_df.iterrows()))\n",
        "start_position = last_processed_idx + 1\n",
        "\n",
        "if start_position > 0:\n",
        "    print(f\"Skipping {start_position} already-processed entries...\")\n",
        "\n",
        "for i, (idx, row) in entries_to_process[start_position:]:\n",
        "    # Progress reporting\n",
        "    if (i + 1) % PROGRESS_REPORT_INTERVAL == 0:\n",
        "        print(f\"  {i+1}/{len(process_df)} - completions:{stats['completed']}, parents:{stats['parents']}, add-ons:{stats['add_ons']}\")\n",
        "\n",
        "    # Evaluate entry\n",
        "    result = evaluate_entry(row, LINES)\n",
        "    results[idx] = result\n",
        "\n",
        "    # Update statistics\n",
        "    if result['needs_completion']:\n",
        "        stats['completed'] += 1\n",
        "    if result['parent_code']:\n",
        "        stats['parents'] += 1\n",
        "    if result['is_add_on']:\n",
        "        stats['add_ons'] += 1\n",
        "    if result['age_restriction']:\n",
        "        stats['age_restricted'] += 1\n",
        "    if result['setting_restriction']:\n",
        "        stats['setting_restricted'] += 1\n",
        "    if result['exclusions']:\n",
        "        stats['has_exclusions'] += 1\n",
        "\n",
        "    # Save checkpoint periodically\n",
        "    if (i + 1) % CHECKPOINT_INTERVAL == 0:\n",
        "        save_checkpoint(results, stats, i)\n",
        "\n",
        "    time.sleep(API_CALL_DELAY_SECONDS)\n",
        "\n",
        "# Final checkpoint save\n",
        "save_checkpoint(results, stats, len(process_df) - 1)\n",
        "\n",
        "print(f\"\\n✓ Phase 2 complete!\")\n",
        "print(f\"  Descriptions completed: {stats['completed']}\")\n",
        "print(f\"  Parent codes: {stats['parents']}\")\n",
        "print(f\"  Add-on fees: {stats['add_ons']}\")\n",
        "print(f\"  Age restricted: {stats['age_restricted']}\")\n",
        "print(f\"  Setting restricted: {stats['setting_restricted']}\")\n",
        "print(f\"  Has exclusions: {stats['has_exclusions']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWYa3f8KzaUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "934fa93f-bfc6-4d1c-e47d-aa46d30af3a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied 1 description updates\n",
            "Applied 928 parent codes\n",
            "Applied 322 add-on flags\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# APPLY GPT RESULTS TO DATAFRAME\n",
        "# =============================================================================\n",
        "\n",
        "# Add new columns\n",
        "df['_desc_original'] = df['description']\n",
        "df['add_on_to'] = None\n",
        "df['age_restriction'] = None\n",
        "df['setting_restriction'] = None\n",
        "df['exclusions'] = None\n",
        "\n",
        "# Apply results\n",
        "for idx, result in results.items():\n",
        "    if result['needs_completion']:\n",
        "        df.loc[idx, 'description'] = result['description']\n",
        "    if result['parent_code']:\n",
        "        df.loc[idx, 'parent_code'] = result['parent_code']\n",
        "    # GPT-determined is_add_on overrides parser\n",
        "    df.loc[idx, 'is_add_on'] = result['is_add_on']\n",
        "    if result['add_on_to']:\n",
        "        df.loc[idx, 'add_on_to'] = result['add_on_to']\n",
        "    if result['age_restriction']:\n",
        "        df.loc[idx, 'age_restriction'] = result['age_restriction']\n",
        "    if result['setting_restriction']:\n",
        "        df.loc[idx, 'setting_restriction'] = result['setting_restriction']\n",
        "    if result['exclusions']:\n",
        "        df.loc[idx, 'exclusions'] = result['exclusions']\n",
        "\n",
        "print(f\"Applied {stats['completed']} description updates\")\n",
        "print(f\"Applied {stats['parents']} parent codes\")\n",
        "print(f\"Applied {stats['add_ons']} add-on flags\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF1Hz6sPzaUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03f7c146-2e1b-4e63-d63a-8c2a7e25a68e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample results:\n",
            "\n",
            "--- DESCRIPTION COMPLETIONS ---\n",
            "  8685:\n",
            "    Before: 'Single Dose'\n",
            "    After:  'Single Dose'\n",
            "\n",
            "--- PARENT CODES ---\n",
            "  8595: Consultation-Unassigned Patient -> parent: 8550\n",
            "  8404: Complete or Extensive Re-Assessment and  -> parent: 8552\n",
            "  8558: Behaviour Therapy Conducted Subsequent t -> parent: 8552\n",
            "  8301: Day 2 - 10, Per Day -> parent: 8300\n",
            "  8302: Day 11 Onwards, Per Day -> parent: 8300\n",
            "  8304: Day 2 - 10, Per Day -> parent: 8303\n",
            "  8305: Day 11 Onwards, Per Day -> parent: 8303\n",
            "  8307: Day 2 - 10, Per Day -> parent: 8306\n",
            "\n",
            "--- ADD-ON FEES ---\n",
            "  8561: For Special Calls Made to a Patient’S Ho\n",
            "  8598: For Special Calls Made to the Emergency \n",
            "  8566: For Special Calls Made in Obstetrics\n",
            "  8567: For Special Calls Made in Non-Elective S\n",
            "  8700: Continuing Patient Care Management, Supp\n",
            "  8526: Clinical Teaching Unit (Ctu) Patient Car -> adds to 8520\n",
            "  8700: Continuing Patient Care Management, Supp\n",
            "  8614: Interpretation of Comprehensive Cognitiv\n",
            "\n",
            "--- AGE RESTRICTIONS ---\n",
            "  8626: Patient must be under eighteen (18) years of age.\n",
            "  8626: Patient must be under eighteen (18) years of age.\n",
            "  8664: Patient must be under eighteen (18) years of age.\n",
            "  8520: Patient must be under eighteen (18) years of age.\n",
            "  8626: Patient must be under eighteen (18) years of age.\n",
            "  8626: Patient must be under eighteen (18) years of age.\n",
            "  8664: Patient must be under eighteen (18) years of age.\n",
            "  8626: Patient must be under eighteen (18) years of age.\n",
            "\n",
            "--- SETTING RESTRICTIONS ---\n",
            "  8561: patient’s home\n",
            "  8598: Emergency Department or O.P.D. of a hospital\n",
            "  8700: in-person visit\n",
            "  8526: for each patient admitted to a CTU designated by Manitoba Health\n",
            "  8700: in-person visit\n",
            "  8551: patient who has been transported from another hospital to HSC\n",
            "  8520: Hospital\n",
            "  8436: must take place in person, except in circumstances described in note 9\n",
            "\n",
            "--- EXCLUSIONS ---\n",
            "  8561: may be claimed in addition to the benefits listed for assess\n",
            "  8598: may be claimed in addition to the benefits listed for assess\n",
            "  8566: Special Call benefit may be claimed in addition to the benef\n",
            "  8645: Time spent performing procedures for which another tariff is\n",
            "  8646: Time spent performing procedures for which another tariff is\n",
            "  8647: Time spent performing procedures for which another tariff is\n",
            "  8626: Time spent performing procedures for which another tariff is\n",
            "  8700: May be claimed in addition to an in-person visit tariff excl\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# DISPLAY SAMPLE RESULTS\n",
        "# =============================================================================\n",
        "\n",
        "def display_sample_results(results: Dict, df: pd.DataFrame, category: str,\n",
        "                           filter_fn, format_fn, limit: int = 8):\n",
        "    \"\"\"Display sample results for a given category.\"\"\"\n",
        "    print(f\"\\n--- {category} ---\")\n",
        "    items = [(idx, r) for idx, r in results.items() if filter_fn(r)][:limit]\n",
        "    for idx, result in items:\n",
        "        row = df.loc[idx]\n",
        "        print(format_fn(row, result))\n",
        "\n",
        "\n",
        "print(\"\\nSample results:\")\n",
        "\n",
        "# Description completions\n",
        "display_sample_results(\n",
        "    results, df, \"DESCRIPTION COMPLETIONS\",\n",
        "    lambda r: r['needs_completion'],\n",
        "    lambda row, r: (\n",
        "        f\"  {row['tariff_code']}:{' [parent: ' + str(row['parent_code']) + ']' if pd.notna(row['parent_code']) else ''}\\n\"\n",
        "        f\"    Before: '{row['_desc_original']}'\\n\"\n",
        "        f\"    After:  '{row['description']}'\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Parent codes\n",
        "display_sample_results(\n",
        "    results, df, \"PARENT CODES\",\n",
        "    lambda r: r['parent_code'],\n",
        "    lambda row, r: f\"  {row['tariff_code']}: {row['description'][:40]} -> parent: {r['parent_code']}\"\n",
        ")\n",
        "\n",
        "# Add-on fees\n",
        "display_sample_results(\n",
        "    results, df, \"ADD-ON FEES\",\n",
        "    lambda r: r['is_add_on'],\n",
        "    lambda row, r: (\n",
        "        f\"  {row['tariff_code']}: {row['description'][:40]}\"\n",
        "        f\"{' -> adds to ' + r['add_on_to'] if r['add_on_to'] else ''}\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Age restrictions\n",
        "display_sample_results(\n",
        "    results, df, \"AGE RESTRICTIONS\",\n",
        "    lambda r: r['age_restriction'],\n",
        "    lambda row, r: f\"  {row['tariff_code']}: {r['age_restriction']}\"\n",
        ")\n",
        "\n",
        "# Setting restrictions\n",
        "display_sample_results(\n",
        "    results, df, \"SETTING RESTRICTIONS\",\n",
        "    lambda r: r['setting_restriction'],\n",
        "    lambda row, r: f\"  {row['tariff_code']}: {r['setting_restriction']}\"\n",
        ")\n",
        "\n",
        "# Exclusions\n",
        "display_sample_results(\n",
        "    results, df, \"EXCLUSIONS\",\n",
        "    lambda r: r['exclusions'],\n",
        "    lambda row, r: f\"  {row['tariff_code']}: {r['exclusions'][:60]}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PtFe57TzaUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b0e344-37fc-411b-d0d6-734974164db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final dataset: 4607 rows x 28 columns\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# FINAL CLEANUP AND COLUMN ORDERING\n",
        "# =============================================================================\n",
        "\n",
        "# Drop temporary columns\n",
        "drop_cols = ['_desc_original']\n",
        "df_final = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "# Reorder columns to match output spec\n",
        "df_final = df_final[[c for c in OUTPUT_COLUMNS if c in df_final.columns]]\n",
        "\n",
        "print(f\"Final dataset: {len(df_final)} rows x {len(df_final.columns)} columns\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CWmVQHpzaUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10e362aa-81ef-41db-8219-9d8f95b91d80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "FINAL SUMMARY\n",
            "============================================================\n",
            "\n",
            "Total entries: 4,607\n",
            "Unique codes: 3,782\n",
            "\n",
            "Fee coverage:\n",
            "  Has fee: 4,437 (96.3%)\n",
            "  By Report: 204\n",
            "  TEC/PRO: 248\n",
            "\n",
            "Hierarchy:\n",
            "  Has category (L2): 4,511\n",
            "  Has subcategory (L3): 1,976\n",
            "  Has subsubcategory (L4): 24\n",
            "\n",
            "GPT Review:\n",
            "  Entries reviewed: 4607\n",
            "  Descriptions completed: 1\n",
            "  Parent codes: 928\n",
            "  Add-on fees: 322\n",
            "  Age restrictions: 162\n",
            "  Setting restrictions: 169\n",
            "  Exclusions: 386\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# FINAL SUMMARY\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nTotal entries: {len(df_final):,}\")\n",
        "print(f\"Unique codes: {df_final['tariff_code'].nunique():,}\")\n",
        "\n",
        "print(f\"\\nFee coverage:\")\n",
        "print(f\"  Has fee: {df_final['fee_total'].notna().sum():,} ({100*df_final['fee_total'].notna().sum()/len(df_final):.1f}%)\")\n",
        "print(f\"  By Report: {df_final['is_by_report'].sum():,}\")\n",
        "print(f\"  TEC/PRO: {df_final['fee_technical'].notna().sum():,}\")\n",
        "\n",
        "print(f\"\\nHierarchy:\")\n",
        "print(f\"  Has category (L2): {(df_final['category'] != '').sum():,}\")\n",
        "print(f\"  Has subcategory (L3): {(df_final['subcategory'] != '').sum():,}\")\n",
        "print(f\"  Has subsubcategory (L4): {(df_final['subsubcategory'] != '').sum():,}\")\n",
        "\n",
        "print(f\"\\nGPT Review:\")\n",
        "print(f\"  Entries reviewed: {len(results)}\")\n",
        "print(f\"  Descriptions completed: {stats['completed']}\")\n",
        "print(f\"  Parent codes: {df_final['parent_code'].notna().sum():,}\")\n",
        "print(f\"  Add-on fees: {df_final['is_add_on'].sum():,}\")\n",
        "print(f\"  Age restrictions: {df_final['age_restriction'].notna().sum():,}\")\n",
        "print(f\"  Setting restrictions: {df_final['setting_restriction'].notna().sum():,}\")\n",
        "print(f\"  Exclusions: {df_final['exclusions'].notna().sum():,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGsgDZ76zaUi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8a1acb3f-6374-47c4-d4dc-c23b827b1552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Saved mb_tariffs_enriched.csv\n",
            "✓ Checkpoint file removed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6569c530-c1b1-463c-b04a-5deb55987fb8\", \"mb_tariffs_enriched.csv\", 1165063)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# EXPORT FINAL OUTPUT\n",
        "# =============================================================================\n",
        "\n",
        "OUTPUT_FILE = 'mb_tariffs_enriched.csv'\n",
        "\n",
        "df_export = df_final.copy()\n",
        "\n",
        "# Clean code fields\n",
        "df_export['parent_code'] = df_export['parent_code'].apply(clean_tariff_code)\n",
        "df_export['add_on_to'] = df_export['add_on_to'].apply(clean_tariff_code_list)\n",
        "\n",
        "# Prefix codes for Excel compatibility\n",
        "df_export['tariff_code'] = df_export['tariff_code'].apply(prefix_for_excel)\n",
        "df_export['specialty_code'] = df_export['specialty_code'].apply(\n",
        "    lambda x: prefix_for_excel(x) if pd.notna(x) and x != '' else x\n",
        ")\n",
        "\n",
        "df_export.to_csv(OUTPUT_FILE, index=False, encoding='utf-8')\n",
        "print(f\"✓ Saved {OUTPUT_FILE}\")\n",
        "\n",
        "# Clear checkpoint after successful export\n",
        "clear_checkpoint()\n",
        "\n",
        "files.download(OUTPUT_FILE)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}